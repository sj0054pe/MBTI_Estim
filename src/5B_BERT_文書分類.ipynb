{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "5B_BERT_文書分類.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47e7c9189b664ce896e6540009bc07be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b8f6a857bba84c0cae332b6f34d6c5f3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_baff820feb9742a7b4453fc5300b3298",
              "IPY_MODEL_8bfd98052ccc41d6be1dad3f018ee84b",
              "IPY_MODEL_4b86f9d97dbf467492e5913264a06388"
            ]
          }
        },
        "b8f6a857bba84c0cae332b6f34d6c5f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "baff820feb9742a7b4453fc5300b3298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2760b5337e834f72955039e84fcce0fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6a19c6c79f44f7e949f0a8f2a8b8a8f"
          }
        },
        "8bfd98052ccc41d6be1dad3f018ee84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4262f41a763040ef850a7f948a3d48ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9999,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9999,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae397d17b62e4cb69a11334adb75b181"
          }
        },
        "4b86f9d97dbf467492e5913264a06388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a46d15e4cbf4443b7cd094d4500c38c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9999/9999 [00:02&lt;00:00, 4136.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af3a73c127e74ae086f87bfe5ae58fbf"
          }
        },
        "2760b5337e834f72955039e84fcce0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6a19c6c79f44f7e949f0a8f2a8b8a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4262f41a763040ef850a7f948a3d48ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae397d17b62e4cb69a11334adb75b181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a46d15e4cbf4443b7cd094d4500c38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af3a73c127e74ae086f87bfe5ae58fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42da8ffc5d2d459b8dbbc34ff1e3724c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f0fa59294fa540bf9a988525f2c21e8c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_492854d2e5824dbdba931db2b35d59c1",
              "IPY_MODEL_a9eaf20248444fa4995f2c79e6e6994a",
              "IPY_MODEL_b2fbeafb36e6441da9cde0cf0b83d589"
            ]
          }
        },
        "f0fa59294fa540bf9a988525f2c21e8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "492854d2e5824dbdba931db2b35d59c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_89c6582fef1e4065a53cd387c907704c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_247d9a381365419c8999cf29443e76a8"
          }
        },
        "a9eaf20248444fa4995f2c79e6e6994a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aedcc0b725d34eb5bae021289faa4e7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9999,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9999,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8580f90bab3543d79fe8cf5abeb3f39d"
          }
        },
        "b2fbeafb36e6441da9cde0cf0b83d589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19326cec318744809f27246b4e87b638",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9999/9999 [00:06&lt;00:00, 1598.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d60a991091754510b0e8d828f146e4f2"
          }
        },
        "89c6582fef1e4065a53cd387c907704c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "247d9a381365419c8999cf29443e76a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aedcc0b725d34eb5bae021289faa4e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8580f90bab3543d79fe8cf5abeb3f39d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19326cec318744809f27246b4e87b638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d60a991091754510b0e8d828f146e4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sj0054pe/MBTI_Estim/blob/master/src/5B_BERT_%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C6N93XpYPLr"
      },
      "source": [
        "#<center>BERT Twitter 文書分類 </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwHdrkqu1FzS"
      },
      "source": [
        "###<center>参考サイト</center>\n",
        "\n",
        "###<center>https://qiita.com/takubb/items/fd972f0ac3dba909c293</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA7agruVYgR5"
      },
      "source": [
        "1. 準備（ライブラリのインストール）\n",
        "2. データセットの準備\n",
        "3. データの前処理（BERTが受けとれる形式にデータを整形）\n",
        "4. 学習済みモデルのロード\n",
        "5. 訓練（Pre-trainedモデルのファインチューニング）\n",
        "6. 検証"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIu7ycEEYusQ"
      },
      "source": [
        "#0. 作業環境の準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDXDLQ87173r"
      },
      "source": [
        "##0.1. google driveのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umfbnIKHK5tx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62089303-d3c2-4e5b-968e-150c05a1373e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c9RJLU91_UN"
      },
      "source": [
        "##0.2. カレントディレクトリへ移動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "242T3dKmYbmQ",
        "outputId": "1ce7b97a-d3c1-4de6-e1c1-d64d57c821dc"
      },
      "source": [
        "%cd /content/drive/MyDrive/研究室/研究_M2/src"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/研究室/研究_M2/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjpE_QDS2Ca9"
      },
      "source": [
        "##0.3. GPUへ接続"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A6tMRaPYtwe"
      },
      "source": [
        "import torch\n",
        "# GPUが使えれば利用する設定\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75NJeaYt2FPa"
      },
      "source": [
        "##0.4. 現在時刻の取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1Gxsj0s0-Ul"
      },
      "source": [
        "import datetime\n",
        "import pytz\n",
        "\n",
        "def pull_Datetime():\n",
        "  DATETIME_now = datetime.datetime.now(pytz.timezone('Asia/Tokyo'))\n",
        "  #print(DATETIME_now)\n",
        "\n",
        "  return DATETIME_now"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA23X1OP2JDM"
      },
      "source": [
        "##0.5. 分類モデルの性格指標を指定\n",
        "\n",
        "この指標をもとに、2クラス分類を行う。\n",
        "\n",
        "E or I なら\n",
        "EI指標の分類器を作成する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0mHOn1leOR4"
      },
      "source": [
        "#TYPE_INDEX='EorI_E'\n",
        "#TYPE_INDEX='NorS_N'\n",
        "TYPE_INDEX='ForT_F'\n",
        "#TYPE_INDEX='JorP_J'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ktlj_ar2hF0"
      },
      "source": [
        "##0.6. 学習するデータセットの指定\n",
        "\n",
        "ツイッターの各投稿に、MBTIの16性格がラベリングされている。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht6JZsf0J8AC"
      },
      "source": [
        "TERM='S6'\n",
        "#INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S1_forBERT_2021-10-01.csv'\n",
        "#INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S2_forBERT_2021-10-03.csv'\n",
        "#INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S3_forBERT_2021-10-03.csv'\n",
        "#INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S4_forBERT_2021-10-15.csv'\n",
        "INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S5_forBERT_2021-10-23.csv'\n",
        "#INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S6_forBERT_2021-10-15.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeqhMagu6kL3"
      },
      "source": [
        "##0.7 学習パラメータを指定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF-q9msi6iyP"
      },
      "source": [
        "LEANING_RATE=2e-5\n",
        "BATCH_SIZE=32\n",
        "EPOCH=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YuZBAGNKS37"
      },
      "source": [
        "#1. 準備 (ライブラリのインストール)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmerZUNiYzdG"
      },
      "source": [
        "Hugging Face Library 'Transformer' のダウンロード\n",
        "\n",
        "* transformers\n",
        "* 最新のNLPモデルを利用できるライブラリ\n",
        "* BERTの他にもGPT-2, RoBERTa, XLM, DistilBert, XLNet, T5, CTRL...などの最新モデルや100言語以上の学習済みモデル（Pre-trained model）を利用可能"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvUfHhiHYzJR",
        "outputId": "ed12ea16-d6c3-4310-a780-0a47f06e2169"
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3\n",
        "\n",
        "#参考サイト (https://qiita.com/takubb/items/fd972f0ac3dba909c293) では欠けているライブラリ\n",
        "!pip install fugashi\n",
        "!pip install ipadic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "aptitude is already the newest version (0.8.10-6ubuntu1).\n",
            "swig is already the newest version (3.0.12-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.9)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.16)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.9)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.16)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "No packages will be installed, upgraded, or removed.\n",
            "0 packages upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 0 B of archives. After unpacking 0 B will be used.\n",
            "                            \n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: fugashi in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied: ipadic in /usr/local/lib/python3.7/dist-packages (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJtypZI6Y6kx"
      },
      "source": [
        "#2. データセットの準備\n",
        "\n",
        "##2.1.準備したツイートデータをダウンロードする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "xxb7wakmY46L",
        "outputId": "0cad4b5b-6e74-409b-f40d-8ca342641ec5"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('%s' % INPUT_CSV_v6, engine='python')\n",
        "\n",
        "# データの確認\n",
        "print(f'データサイズ： {df.shape}')\n",
        "\n",
        "df[['text', 'tweet_time', 'MBTI_Type','label_EorI','label_NorS','label_ForT','label_JorP']].sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "データサイズ： (10003, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_time</th>\n",
              "      <th>MBTI_Type</th>\n",
              "      <th>label_EorI</th>\n",
              "      <th>label_NorS</th>\n",
              "      <th>label_ForT</th>\n",
              "      <th>label_JorP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6972</th>\n",
              "      <td>食べ放題、お酒のみながら夜通しゲーム、雑魚寝、次の日にくだくだしながら飯を食う。 凄く、大学...</td>\n",
              "      <td>2017-11-05 04:29:14+00:00</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>666</th>\n",
              "      <td>私コンビニでバイトして事があるので実際にあるあるでしたね…ｗ</td>\n",
              "      <td>2017-12-15 16:09:17+00:00</td>\n",
              "      <td>INFP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4496</th>\n",
              "      <td>Java 学習コース Ⅰを修了しました！https://t.co/b48xOFcteB #P...</td>\n",
              "      <td>2017-08-19 17:45:48+00:00</td>\n",
              "      <td>ISFJ</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>F</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2328</th>\n",
              "      <td>今日はえっちしないよ。心に決めてるんだ</td>\n",
              "      <td>2017-12-31 13:50:39+00:00</td>\n",
              "      <td>ISFP</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2434</th>\n",
              "      <td>顔は変わってないわ人聞き悪いｗｗｗｗｗｗそんな老けてますか、、、（笑）来年はもっといっぱいお...</td>\n",
              "      <td>2017-12-31 07:22:34+00:00</td>\n",
              "      <td>ISTP</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8976</th>\n",
              "      <td>昨日見つかったものも今日には見つけられないのだなぁ</td>\n",
              "      <td>2017-10-27 17:01:59+00:00</td>\n",
              "      <td>ISFJ</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>F</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6574</th>\n",
              "      <td>買い逃してたグッズ買った✨きゃわいい～～～～～</td>\n",
              "      <td>2017-12-30 15:06:43+00:00</td>\n",
              "      <td>INFP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6280</th>\n",
              "      <td>バーティカルでもアングルでもどっちでも良かったんだけど、まさかのどっちも見つからないって言う...</td>\n",
              "      <td>2017-10-31 11:00:07+00:00</td>\n",
              "      <td>ESTP</td>\n",
              "      <td>E</td>\n",
              "      <td>S</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1760</th>\n",
              "      <td>すいません！雪玉製造機とは？！ 圧雪玉禁止って、マジで？！</td>\n",
              "      <td>2017-11-19 06:29:19+00:00</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1928</th>\n",
              "      <td>FGOにもお札編成が出たりするのかな……</td>\n",
              "      <td>2017-12-26 06:18:29+00:00</td>\n",
              "      <td>INFP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ... label_JorP\n",
              "6972  食べ放題、お酒のみながら夜通しゲーム、雑魚寝、次の日にくだくだしながら飯を食う。 凄く、大学...  ...          J\n",
              "666                      私コンビニでバイトして事があるので実際にあるあるでしたね…ｗ  ...          P\n",
              "4496  Java 学習コース Ⅰを修了しました！https://t.co/b48xOFcteB #P...  ...          J\n",
              "2328                                今日はえっちしないよ。心に決めてるんだ  ...          P\n",
              "2434  顔は変わってないわ人聞き悪いｗｗｗｗｗｗそんな老けてますか、、、（笑）来年はもっといっぱいお...  ...          P\n",
              "8976                          昨日見つかったものも今日には見つけられないのだなぁ  ...          J\n",
              "6574                            買い逃してたグッズ買った✨きゃわいい～～～～～  ...          P\n",
              "6280  バーティカルでもアングルでもどっちでも良かったんだけど、まさかのどっちも見つからないって言う...  ...          P\n",
              "1760                      すいません！雪玉製造機とは？！ 圧雪玉禁止って、マジで？！  ...          J\n",
              "1928                               FGOにもお札編成が出たりするのかな……  ...          P\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeUswwipVfUJ",
        "outputId": "ab200c11-5cdb-40ee-b78e-114925ba2fc3"
      },
      "source": [
        "df.dropna(how='any', axis=0, inplace=True)\n",
        "print(f'データサイズ： {df.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "データサイズ： (9999, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdmhA807JGmJ"
      },
      "source": [
        "##2.2. 性格指標のone-hot化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "A8Sod6gSJDIK",
        "outputId": "4f0ae283-1b00-467c-d908-76a081aead7d"
      },
      "source": [
        "df=pd.get_dummies(df, columns=[\"label_EorI\", \"label_NorS\", \"label_ForT\", \"label_JorP\"], sparse=True)\n",
        "df[['text', 'tweet_time', 'MBTI_Type','label_EorI_E','label_NorS_N','label_ForT_F','label_JorP_J']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_time</th>\n",
              "      <th>MBTI_Type</th>\n",
              "      <th>label_EorI_E</th>\n",
              "      <th>label_NorS_N</th>\n",
              "      <th>label_ForT_F</th>\n",
              "      <th>label_JorP_J</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>とても久しぶりな動画製作中... 　覚えたことは早速使いたい感が編集TLに出てる</td>\n",
              "      <td>2017-11-25 15:53:33+00:00</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>道中大破の撤退を減らすには艦隊司令部を置けばいいんだろうけどそうするとどう考えてもボスで優勢...</td>\n",
              "      <td>2017-12-04 14:38:25+00:00</td>\n",
              "      <td>ISTJ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#セレスティア・ルーデンベルク生誕祭2017 誕生日おめでとうございます！！ ドッヒャーは未...</td>\n",
              "      <td>2017-11-22 15:11:32+00:00</td>\n",
              "      <td>INFP</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>今回は無かったですけど、タイミング次第であるみたいです😁</td>\n",
              "      <td>2017-12-24 02:17:13+00:00</td>\n",
              "      <td>INFP</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>最後のアレで持ってかれたw直虎面白かった(そして泣いた)直政の元服における口上も最高でしたヽ...</td>\n",
              "      <td>2017-12-17 10:00:02+00:00</td>\n",
              "      <td>ISTP</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>今日初めて大学生相手に研修をやりましたが、とてもしんどかった。</td>\n",
              "      <td>2017-02-20 07:50:57+00:00</td>\n",
              "      <td>ENTP</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>HKT48の最高かよにハマってしまった。。。</td>\n",
              "      <td>2017-05-20 15:05:43+00:00</td>\n",
              "      <td>INTP</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>キングハサンは本人のカード性能理解しないと難しいなぁ</td>\n",
              "      <td>2017-12-29 17:23:09+00:00</td>\n",
              "      <td>INTP</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10001</th>\n",
              "      <td>まぁ僕は両方とNFSPBもハンコン買いますが(バイト代消滅不可避) あとgtsport はナ...</td>\n",
              "      <td>2017-10-19 12:50:19+00:00</td>\n",
              "      <td>INFP</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10002</th>\n",
              "      <td>ですです! 覚醒結晶が30魔石で各停はおいしいですもんねᏊˊ•ﻌ•ˋᏊ 欲を言えばルーンの方...</td>\n",
              "      <td>2017-11-27 14:07:33+00:00</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9999 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  ... label_JorP_J\n",
              "0               とても久しぶりな動画製作中... 　覚えたことは早速使いたい感が編集TLに出てる  ...            1\n",
              "1      道中大破の撤退を減らすには艦隊司令部を置けばいいんだろうけどそうするとどう考えてもボスで優勢...  ...            1\n",
              "2      #セレスティア・ルーデンベルク生誕祭2017 誕生日おめでとうございます！！ ドッヒャーは未...  ...            0\n",
              "3                           今回は無かったですけど、タイミング次第であるみたいです😁  ...            0\n",
              "4      最後のアレで持ってかれたw直虎面白かった(そして泣いた)直政の元服における口上も最高でしたヽ...  ...            0\n",
              "...                                                  ...  ...          ...\n",
              "9998                     今日初めて大学生相手に研修をやりましたが、とてもしんどかった。  ...            0\n",
              "9999                              HKT48の最高かよにハマってしまった。。。  ...            0\n",
              "10000                         キングハサンは本人のカード性能理解しないと難しいなぁ  ...            0\n",
              "10001  まぁ僕は両方とNFSPBもハンコン買いますが(バイト代消滅不可避) あとgtsport はナ...  ...            0\n",
              "10002  ですです! 覚醒結晶が30魔石で各停はおいしいですもんねᏊˊ•ﻌ•ˋᏊ 欲を言えばルーンの方...  ...            1\n",
              "\n",
              "[9999 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RLwGStUi5Fu"
      },
      "source": [
        "sentences= df['text'].values #sentences = df.sentence.values\n",
        "labels= df['label_%s' % TYPE_INDEX].values #labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMl0WC3MOECX",
        "outputId": "0c0c106a-0d14-49cc-90d0-abbe6ccd554a"
      },
      "source": [
        "labels "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, ...]\n",
              "Fill: 0\n",
              "IntIndex\n",
              "Indices: array([   0,    2,    3, ..., 9993, 9997, 9998], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUtOVe9SuJqt",
        "outputId": "a3fe7071-ee29-4007-8621-3e9f7a68a4bd"
      },
      "source": [
        "print(len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21UWv4KfjCB3"
      },
      "source": [
        "#3. データの前処理（BERTが受けとれる形式にデータを整形）\n",
        "\n",
        "BERTでは基本的に学習済みモデルを利用する為、そのモデルが読み込めるフォーマットにデータを変換する必要があります\n",
        "具体的には、以下の4つ手続きが必要になります\n",
        "\n",
        "1. BERT Tokenizerを用いて単語分割・IDへ変換\n",
        ">* 学習済みモデルの作成時と同じtokenizer（形態素解析器）を利用する必要がある\n",
        ">* 日本語ではMecabやJuman++を利用されることが多い\n",
        "\n",
        "2. Special tokenの追加\n",
        ">* 文章の最後に[SEP]という単語する\n",
        ">* 文章のはじめに[CLS]という単語を追加する（分類問題に利用される）\n",
        "3. 文章の長さの固定\n",
        ">* BERTでは全ての文書の長さ（単語の数）を同じにする必要がある（1文章あたりの最大の単語数は512単語）\n",
        ">* そこで、Padding/Truncatingを用いて固定長に変換する\n",
        ">* Paddingとは、指定した長さに満たない文章を[Pad]という意味を持たない単語の埋める処理\n",
        ">* Truncatingとは、指定した長さを超える単語を切り捨てること\n",
        "4. Attention mask arrayの作成\n",
        ">* [Padding]を0、それ以外のTokenを1とした配列\n",
        ">* 一見ややこししそう見えますが、どれもTransformerのライブラリでサポートされているので、簡単に実行できます\n",
        "\n",
        "また、以下のイメージも参考にモデルの全体像と照らし合わせながら前処理内容をみるとイメージが沸きやすいかもしれません"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGL6B-xKjI3M"
      },
      "source": [
        "##3.1. BERT Tokenizerを用いて単語分割・IDへ変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w1Z3BvUjF77",
        "outputId": "45761c01-63e6-45c1-8d9f-b0c5633ee9eb"
      },
      "source": [
        "## Tokenizerの準備\n",
        "from transformers import BertJapaneseTokenizer\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "\n",
        "#念の為、確認\n",
        "## テスト実行\n",
        "# 元文章\n",
        "print(' Original: ', sentences[0])\n",
        "# Tokenizer\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "# Token-id\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  とても久しぶりな動画製作中... 　覚えたことは早速使いたい感が編集TLに出てる\n",
            "Tokenized:  ['とても', '久', '##し', '##ぶり', 'な', '動画', '製作', '中', '...', '覚え', 'た', 'こと', 'は', '早速', '使い', 'たい', '感', 'が', '編集', 'T', '##L', 'に', '出', 'てる']\n",
            "Token IDs:  [8567, 1658, 28454, 14657, 18, 4884, 1300, 51, 3215, 8806, 10, 45, 9, 21966, 3276, 1549, 832, 14, 2028, 260, 28743, 7, 71, 7134]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igADsm2KjVcE"
      },
      "source": [
        "##3.2. 次に文章の長さを固定する為に、文章あたりの最大単語数を確認します\n",
        "\n",
        "ここでは、以下の方法で最大単語数を確認していますが、最大単語数は決め打ちで設定することも可能です"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6CO0d-HCDja"
      },
      "source": [
        "# print(sentences[15806])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "47e7c9189b664ce896e6540009bc07be",
            "b8f6a857bba84c0cae332b6f34d6c5f3",
            "baff820feb9742a7b4453fc5300b3298",
            "8bfd98052ccc41d6be1dad3f018ee84b",
            "4b86f9d97dbf467492e5913264a06388",
            "2760b5337e834f72955039e84fcce0fb",
            "a6a19c6c79f44f7e949f0a8f2a8b8a8f",
            "4262f41a763040ef850a7f948a3d48ca",
            "ae397d17b62e4cb69a11334adb75b181",
            "1a46d15e4cbf4443b7cd094d4500c38c",
            "af3a73c127e74ae086f87bfe5ae58fbf"
          ]
        },
        "id": "wqzm2jSYjYtx",
        "outputId": "2e480e8a-181d-461d-d32a-4db7d10aa508"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# 最大単語数の確認\n",
        "max_len = []\n",
        "# 1文づつ処理\n",
        "len_sentences = len(sentences)\n",
        "for sent in tqdm(sentences):\n",
        "    # Tokenizeで分割\n",
        "    token_words = tokenizer.tokenize(sent)\n",
        "    # 文章数を取得してリストへ格納\n",
        "    max_len.append(len(token_words))\n",
        "# 最大の値を確認\n",
        "len_max=max(max_len)\n",
        "#len_q0, len_q25, len_q50, len_q75, len_q100=np.percentile(max_len,  [0, 25, 50, 75, 100])\n",
        "#len_q75=int(len_q75)\n",
        "print('最大単語数: ', max(max_len))\n",
        "print('上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47e7c9189b664ce896e6540009bc07be",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9999 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最大単語数:  129\n",
            "上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Iy684SijdEO"
      },
      "source": [
        "##3.3. Tokenizerと最大単語数の確認がとれたので、全ての文章に一括して処理を行います\n",
        "\n",
        "tokenizer.encode_plusを利用するとまとめて処理が行えます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "42da8ffc5d2d459b8dbbc34ff1e3724c",
            "f0fa59294fa540bf9a988525f2c21e8c",
            "492854d2e5824dbdba931db2b35d59c1",
            "a9eaf20248444fa4995f2c79e6e6994a",
            "b2fbeafb36e6441da9cde0cf0b83d589",
            "89c6582fef1e4065a53cd387c907704c",
            "247d9a381365419c8999cf29443e76a8",
            "aedcc0b725d34eb5bae021289faa4e7e",
            "8580f90bab3543d79fe8cf5abeb3f39d",
            "19326cec318744809f27246b4e87b638",
            "d60a991091754510b0e8d828f146e4f2"
          ]
        },
        "id": "sWPRjjZIjfRC",
        "outputId": "241e277f-b30e-45af-d707-994ef30bd977"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# 1文づつ処理\n",
        "for sent in tqdm(sentences):\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True, # Special Tokenの追加\n",
        "                        max_length = len_max,        # 文章の長さを固定（Padding/Trancatinating）#mayo\n",
        "                        pad_to_max_length = True,# PADDINGで埋める\n",
        "                        return_attention_mask = True,   # Attention maksの作成\n",
        "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
        "                   )\n",
        "\n",
        "    # 単語IDを取得    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # Attention　maskの取得\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42da8ffc5d2d459b8dbbc34ff1e3724c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9999 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvi8VKqgIkpj"
      },
      "source": [
        "##labelをtensor型に変換\n",
        "\n",
        "labelはpd.get_dummiesでone-hotにしてます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4ZMdlFhIanB"
      },
      "source": [
        "# tenosor型に変換\n",
        "labels = torch.tensor(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdZuAV8oJHk9"
      },
      "source": [
        "## BERTの前処理が正常に実行されたか確認\n",
        "\n",
        "前処理は、\n",
        "\n",
        "Special tokenの追加、文章の長さの固定、Attention mask arrayの作成\n",
        "\n",
        "である。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LelL1aVJGqT",
        "outputId": "88abe7da-d302-4633-93d9-940f3709f8fd"
      },
      "source": [
        "# 確認\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  とても久しぶりな動画製作中... 　覚えたことは早速使いたい感が編集TLに出てる\n",
            "Token IDs: tensor([    2,  8567,  1658, 28454, 14657,    18,  4884,  1300,    51,  3215,\n",
            "         8806,    10,    45,     9, 21966,  3276,  1549,   832,    14,  2028,\n",
            "          260, 28743,     7,    71,  7134,     3,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K1TIhOUjiAR"
      },
      "source": [
        "1つ目の文章の前処理結果です\n",
        "\n",
        "元々、日本語テキストだった文章がID化されています\n",
        "\n",
        "Token IDsの最初に単語IDはSpecial tokenの[CLS]を表し、後半の0埋めが[Pad]を示しています\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Original:  旧式Macで禁断のパワーアップ！最新PCやソフトを一挙にチェック\n",
        "Token IDs: tensor([    2, 18718,  8653,    12,  1763, 29135,     5, 20734,   679,  6215,\n",
        "         3794,    49,  1604,    11, 24598,     7,  9398,     3,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF-tpHIxjnbX"
      },
      "source": [
        "##3.5. データローダの適用とデータの分割\n",
        "\n",
        "ここまでで、前処理が完了したので、90%を訓練データ、10％をテストデータに分割して、pytorchで学習を行う為に、データローダーへ変換しておきます\n",
        "\n",
        "データローダーの説明は、pytorchの基本的な操作なので本記事では割愛します（簡単に言うと、データをバッチごとに分割して、学習を上手くやってくれるデータ型です）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5knJ5xITjikd",
        "outputId": "1d205cb1-c558-4b57-ee87-92b5e5825f70"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# データセットクラスの作成\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# 90%地点のIDを取得\n",
        "# train_size = int(0.9 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "#train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# データセットを分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_dataset, val_dataset  = train_test_split(dataset, train_size=(0.7+0.1))\n",
        "val_dataset, test_dataset  = train_test_split(val_dataset, train_size=(0.7+0.1))\n",
        "\n",
        "print('訓練データ数：{}'.format(len(train_dataset)))\n",
        "print('検証データ数:　{} '.format(len(val_dataset )))\n",
        "print('テストデータ数:　{} '.format(len(test_dataset)))\n",
        "\n",
        "# データローダーの作成\n",
        "batch_size = BATCH_SIZE\n",
        "\n",
        "# 訓練データローダー\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), # ランダムにデータを取得してバッチ化\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# 検証データローダー\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), # 順番にデータを取得してバッチ化\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# 検証データローダー\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), # 順番にデータを取得してバッチ化\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練データ数：7999\n",
            "検証データ数:　1599 \n",
            "テストデータ数:　401 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uuhm0mxWjvRK"
      },
      "source": [
        "#4. 学習済みモデルのロード\n",
        "\n",
        "huggingface transformerのBERTファインチューニングでは以下のタスクをサポートしています\n",
        "全てBERT Pre-trainedモデルをベースとして学習し、出力層のみそれぞれのタスクに適した構成になっています\n",
        "\n",
        "* BertModel\n",
        "* BertForPreTraining\n",
        "*   BertForMaskedLM\n",
        "*   BertForNextSentencePrediction\n",
        "*   BertForSequenceClassification\n",
        "*   BertForTokenClassification\n",
        "* BertForQuestionAnswering\n",
        "\n",
        "公式ドキュメント."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzI8Fkkmj4UR"
      },
      "source": [
        "## BertForSequenceClassification\n",
        "\n",
        "今回は2クラス分類問題なのでBertForSequenceClassificationを利用します\n",
        "\n",
        "BertForSequenceClassificationは**「BERT学習済みモデルの最後の層に分類用のレイヤー追加したネットワーク構成」**です\n",
        "\n",
        "データを入力することで、学習済みモデル全体と未学習部分の分類機レイヤーの学習が行われます\n",
        "\n",
        "デフォルトでは、モデル全体のパラメーターがファインチューニングされますが、学習させるレイヤーの設定変更も可能です\n",
        "\n",
        "モデルロード時にnum_labelsを変更することで多クラス分類問題へも対応できます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2dsv2NnkIoA",
        "outputId": "174dd9ae-b3c0-4674-f4ed-1f7ec5eb44bf"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# BertForSequenceClassification 学習済みモデルのロード\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"cl-tohoku/bert-base-japanese-whole-word-masking\", # 日本語Pre trainedモデルの指定\n",
        "    num_labels = 2, # ラベル数（今回はBinayなので2、数値を増やせばマルチラベルも対応可）\n",
        "    output_attentions = False, # アテンションベクトルを出力するか\n",
        "    output_hidden_states = False, # 隠れ層を出力するか\n",
        ")\n",
        "\n",
        "# モデルをGPUへ転送\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxggBnjMkMF6"
      },
      "source": [
        "学習済みモデルのロードが完了しました\n",
        "\n",
        "次にこのモデルを手元のデータに合うようにファインチューニングを行います"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrgUL9rIkMmR"
      },
      "source": [
        "#5. 訓練（Pre-trainedモデルのファインチューニング）\n",
        "\n",
        "モデルのファインチューニングは通常のニューラルネットワークの学習と同様で、損失関数と最適化手法（Optimizer）を指定して、学習ループ（任意のバッチサイズとエポックを指定）を回します\n",
        "\n",
        "BERTでは損失関数はすでに定義されているので、ハイパーパラメーターとして、最適化手法とバッチサイズをエポック数だけ指定します\n",
        "\n",
        "ここでは、論文（BERT paper, Appendix A.3）に従って、最適化関数はAdamW（Adam Weight Decay fix）を利用し、ハイパーパラメーターは下記のように設定します\n",
        "![image.png](data:image/png;base64,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![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAboAAAA0CAYAAAD8Ov2ZAAAgAElEQVR4Ae3dBdxFP1kH8Nndit3YXSjYiiAKJjZ2J2Jgd2J3B3aLgV3YYHeL2ILdHZ8v7qePc+fec+973z8v/Pd8Prv3nJ2dne3Z9tSeba0tWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGDiKgddqrd32aKqV4JbEwONMPvask7jHa63dYRL/iIh6qtbak1/ow4/eWnu51tpzlPyeubX28q21GW5KsnV5Lgbu1VrTiNcFGvW5WmsacsHCwC2Jgadsrf1Ha+33Wmv64SMDPGNr7S9ba3/SWlP+6wC4+JjW2lNfR+ZH8rx7a+1PW2u3L+k+v7X2b621Ny1xLj+ht9+HDPFuH6219uuttd8s4Vd7utdurX3xjvBqk3y3ov65tfYXrbXH30owiX+W1trrTuKfqLX2n621zyrPPqrHPVOJyyX6/LGttcdIxE35f4HW2ku21lRoBj/ZK/UGs4dDHKnmsYa4S92+cy/H77TWnuZSmQ75GLga9Z+uceAOn1y3CwMPx8Dr9b73iQM+3qi1dr8dAcEMPGlr7VVaa0+YiGv6p9kYL394TfnL9rP7N95+4xvq+JgbzxLt+bE0SVv/P6V/+49aa0/bH6Q8mN3L9Dj0071w15pBv8bofqMwOQzv1/ozwnsYIDzC59+UuDx7u0m+W1EY3c9vPZzEwyHGG4ZGe1Mn4ZV7/BeVuC/pcbS6pHvBnu9b92efM/nOoSh8Qx5v1lp7247biwpPJA0VnHFzBfvp/rxKNSlwlTzfq7X2sNbaR+Th8K9BP7y19nxD/J7bl22t/Usvxw+01maSxJ58jqUJo3vosYRXeA6PX907lgH0M12ae2Q1Wb1Ea02bvPkVcHKpVz+jtfaLrbVX3MjwHfvzdynPXf/xRvit1to3tNaev6QnJf9Ca+2nStwlLmkKxuHPtta+roevaa1FevbsUHjfUogX72n/obV2mxI/u8QAzu17183o3rLXQ7vO4Bm6UDpqV0l7u9baj/U0hFfX4vbCY7fWfqIzMGUBCPKPdE32VVtr0vxSL2dtg5784X/6zBNMwqhxoXPa+CPryweuCTN3noR/b609ZBIvbRhSzZb29XH9275PQz/U12bPfrtkGAEBwzoGL9bxiTnP8v3xjTIfy/f/PQ+jo9nNYMboSDIPaq29X3kBx1dQBWb+G+EH+/PvGh8cuUdkMB55Iy5j5zjy+kmPr5vRMcEgqvcoGiNCpENgeqShmwov3Fp7pYlZ7S69bT7sBhT823pZqnZTi6WM+hHmEdCHxf1ZZzIYjYB4MSV6hkg+b38hphz9/FKg3/1j/5bv1YCwPu6OUE1FGL08fuhIAY35X+l137KSfF4vm/KNIcKnb43P6v17HinH7PFT9HI9cNLnpNce39LrOWN0mHeIJwE8xFvcXsb+rq21b+6E+NNbawkEEN92/+29DPoKhvxWQ2W0X23P8Zq2h8a9UFcSPP/gfi/uUFkxtDG/Y/cEty14/c7waHQ0OeE1+ze+vMR9VY+jvSZdVYTUiTBgTG3NFcKL8fivPS908W/7NUXAWP67fi/Ne28Vem/8OYwuHJsd+En6h+pg/crJx9m6NcIpKjiGag7Ae6TrrcE4+dxZUdfJ6Jh+mSEiYcMb6ZLZQCfhiKCxtwSOsyp0wZe+r7fDaOI2EGnxW1rUBYtwNKurMLrRZOhjBLZf7vVG3MB1MLr79m/QCCIQMpXRAs6B1+j5feuRl5mGMAHjC8Gewft0jZ3WLvx9T0+rTVz+mcvk9VfDM+bXU8FcF0L+IsOLiKh5TN9JmDG6MMEv61oXzcu1dzzbA2mLfGfP/8hICCBfW7T0aOv+xatPGPIs/587UFAMoeaXa/kwf+a+/u8VOpRL2Z+s48wYdy8Q2H3DWHAv7Qg0R6bcKlQmjfTf3fNgdSDosyxEqTKOAY3duPMtggRT6dlwDqN7uiKBMkcGPr4XSgd9zkS21qRPI1JV94DBCgneI13HRr7n3XPTXBejI9WQKO/YC4agVUlGHR/QWnub1hqGchNhi9HdpLJemtGp2z17H8ycyqUZnUH/u621B3cvthmemZUIfFuBqbLCG/cyI+zHgBSfscm0eww+t6d/90nCd+rPCMJXBYLtFvPlmPHqrbUf7d8bGR0Grk7G2NOXgrjOuNsz/xNGR/h89hIQcHSzxiHCvjkyunyeMPvSJVQNiAlUfdAIWoxrwTXT3amAcZ4yR0eB4IvxCuVDaFT6xbF/ziczIFBoxxHeredNIKqCvXvfUvcK39Tj+WeMgnZNd/D6HEYnw0/tHyc5pNMg6AYjdZ8XT4A6rwJMQCSrQ8A0aaDEbETLYca4JSCMDoNlk987ma/MtdOPbrcm0iNFhrAwydAYTNrCzSe31p64d+7Mfb5o7wikJtot06HrALzTBJ87EcM/KQkRfMM+aTzinnZpMpnU5pvm2zhF1Py0ozSRtpgq3MfdWJndE2ZG4CnHtKmMM0/W1M972vh1eh238I5QBc8zwec6GF3miWjj4BxGd6zc2ihODDNG95l9PBAka7h/7zuVaCqj/qZPbc1t/XdN/vf3G3t62tohU5k3XqqnnRHSMB7u6FcBbaz8x+Z9I+2PjI6lxPt13ijlIVB4tmeuLoyOeZsmlIA2YUq595+51BmjI8z4Zg2UgQr6FQbK5BdAh2aCLzplzG0F+aj71nPx1Tr2ab1syvTRXUOThjZfwx90bbrGud5q7zfp+T5PKtTpRhSYzHt6HOEEjsax7f6ve15oyVlwLqOrWl01R86YksZXgWOmFMQcQakdYjagUlHpIfMqoXqThtHl+2zGX7hjfUw85vLeaMYjFLx/Z5xMRaTKzPl8YK8vbyOAsRvoQOP+fmvt+wtODDBaBnU/woDvmmivjEznYvZImfxr66pRcxASz/7NFFXTfkEvg/rX+FzHvLA1R6dedQ7HezzWzDcF1E+ZaAcGWfI2XzkjRDEjSocIjXBpRqcvh9jxfATnMLpj5Y4TDUeaEAFecO61Cy2KlD5C+t3I6BBeOJqZjcY83CN65tS8g9Adg3jo3a0k1K+8r39HUCuPT7pMn6oC1yyDLUZnTCvLbI5SnGd13M/yFpe2l35vmDE6eRn/H1AC5glP8CYYz75Be3EfZk2jc08oDDCz7y3PVrrqX0FQ/4qeJ0arXATTMeiLnOfGePd1XKechCbfr0sjQu9GXw2ONdIa+zP4zv58y9lx9s7/iTvG6FRMAcbBJBOmDlrGIaA1ZPC+xUZCZk4uqyF2CGA0nUOMLgx0qzH3xFcCEkaHgYwMl+nq3oMklOqE4OR7I6P7nq6txKuqSm20X+9FhUcosiA1Uoz/TIST1vIdzjnmMkJIIyFheIn70tYaLRIxVS9msjj0hNHJD0OlCUgrjTiDDbGhxWkHcSan3cd7K0SpOqMwwUr7510D+dAyr2K9USD1k9a8LtNu2n1mtkqdpL80oxudUTikhPjDecyD18HozNHBvxDhwIB3bz6KQ0jtp8Ff+t04NvVTOOLUsBfiVIG5HoN36PnDmTGjv3nPN83fXBUIzvLa0uyT/xajQ5e8b2yNkPG2x0wbRledLvR9dIoZzXVCtJctRvdBfawarwKCn/kvZd0TOHAA+EFTxmCudMxnTJP7GaOHE1YmGtSYz7H7mQOY5WbeQw8CodnM3BXgR9pZm0mXabFYxuq7u66PMbp4PFYX610Z90TstyrApMnMVYHWQZKoxPt7+/IBZjTvHWJ0pCBawlUCtT0QRpflBYgbMyrzrLIItDESc4UQnKQZGR0XZTb8zGEgbAEEDUFlZoQfBC3myTAC0k7ABLbv1DzY/sURFgCBwr2BynyYQOsTz+sThNH5zrP1OH8hlJ4HZiY1z0ZGx0zDSQlTrSYNJlBzDohEzJypXzWxMfvqK56NcJ2MThvQphMinGF4Vbu8DkZX6/nDvY18J8B0qd0Q1xowGvEjo+MtKP4UppN1qt6LoJXvj//aOBI2c2WIkPkYxO2qwBSpHNYDHoJjjG5mQRIn71MYHSGuamP6NhpR4whw8p0xui3TpXE+Wx4wi7vThtNH8EMLi7ONciScowGF0en71VrG7KuNaxxHF9+aMTqCimcEo0BMx2hWhfQn83czIOjLi+B+FpDkmCJmtvkqcZzjAcY8FxfRmXQZzxsVwHAxDJ0C7GF0PenF/kZGl4wNOKo+IqiTR5vJc/NV1V7PW6iCxqEthQBFW4EfdY8UbeAgHAHEHmGrELNFnTgmMMgnjC5eseJmIQ5EYXSfVD/QWuMl571zGF3mV/SpEZj/5JvJZvXD+EaCpi/MGJ05m+CZ5jnCJU2X1pUqK80+gofvncPojpW71oOQ4LtVSAijY06uIcKHebMKWbTLZF4hAkaNy3XWxPn2FrFJWv/MnawP0gvGxSjg1fSnXNOS5HlMuN5idOZ6vU/AHMHcuGfSHINodNLvDTNG5zuEpTpnhr4FOA/VudfxetR+8l7+0Uz9QhljhSCoxbmjWlvyzuwfXVOWMDraFaGYcEBQtaQs9Ek90RF00XdnjI41yDPONoH07+rDYYoglozZ0jTvMuHK68rLDFKQ+m+Ayty80KlgctFuAN43MVol1OTFeYUqTbWtxMTzm8ToUl7ahkF4Kmgc8ywYG42Q1maBsMldBEKHxJwIBVU6R+wR/QphdMyggZHRZecCaxvhdgwhjGF0mR9MfldhdAazNqeZjJBF0TFhqx8Jb4QtRjemG+/D6EicM4jmUeeuMlDH5QWIRzTIlFee5zC6WVlmcZXZwE2IoW2VSPTaK+YrjJ6ARDgagfORNqhmIBK0/hXz9viO+9T362cPJ3F1/tYYHwWWySu7omwIofy0zEOwxeis+fT+jG4xB3smzTGwdowGg4FXj0kWKP22xrFsYAizReOY3Gx3mwgGqYdyzUKYy6y8LEG25/KecnHWQF9YwtCSrE0jzI4WtTG/jJ/Mo+k/cbKhqVdG5xsEsIyfGaOLU1S1EER4gK9APJtHWpfn6hS8GAcXBQjUyD5gjuAUYNOm/XiXhLGnU43530RGN5Zx7z0thzkOoyNJkk4IAToCiYnWQAMiTVU4l9HRnuF+1KJJWDpVTKFhdOM6p6swOusDfdu6ydH7NNvJxRQ4q5/6n8vo4vpuQn8EjIt2rGzVbJWBOjI678dNHxE3HsB1MrpokQi0cjJNxjqQrafSR+L1XOc/ehEf7rzgfXOtsZDExLSlcXiX8GSs5p3kN/7TDL+jl9F3EmxhFe/R8Z1T73n5zoSlmk8YxOh1qY0yHVIFQmvyCJaezQRveas7HFfz3HjNCoFhjvH1Xh7BIyYAR8a8MRBnnggdqQfib+eoBOX13hajQ0v4DkhDgI6Xahid+pgyiRkeDTJfzlI3AqYon9Br11dldOYMLQ2rEA9PTkHwo38rl++9R03Yr+Eg02dxlJkkOy9KASJ96xTxAjyWG++bKuUhZJFajr07Pn9UYnTqphFJRFtSFe02xDS4mDGCPRodrcqAZibIIktMJ/MTmYg+hdHF7BjbOo09ywd00moeiUkNccb4fJsbsnQk4TDAWf3U/VxGF287gz7zkPLjLGGuwvf1ZwJH4BCjY2WIVSIM5boYnW/FmYDUmrlYHrcg44HpDWS+dbYdHvwiduoL77bncy3oG+eCeSDEPOYneKZRMnlVD1/z7tFGz/2W8aK8WXs6yycMYmR00pr39b5yYRxMYhiGuDonPOZ7bCcT7+8N0b7D6MJ0OZ7JY2R0VfNRrpRlZHTM2jHByocPQTUPVkYnH4Jt5nOlN+5oamHE0vCN8IyWVk2X0eh4XGKCmKa5u6TN+Bk1OlMr0oymRr4Amc7CuMLkmMErAzYebM9nSZp8fHvLrDm24a57bqKx9/rAaOcfM+HBh6ggboirdwQDdDbvN76/dZ+BfcgZZevdc+O35ujOza++h0jQjO1BZ1d0TAJj43GKGJHio2nlvRkj2MPovG9dXtqC9BkTBmlSWcApjC5OJzocKZJUSzNKfGV0BKMQQ506nVmnrXOLs/op17mMzrvMbqm3/GljyixO/+TdVSEDdabRSYcYeZc2iPCE0YmD062QdYb1W4eus9cgQQABIvgwbVcplyXA9ksm+RGcLGKf5UtyDx7yT/A4B8zHYWj6bvJi7YlmLk/CxH16v0ga5fMeAfhUQIfgQh5bDi6HGB38ZZPklMe/OM+2AO73aHTapmpw4/VMo7sEo4PzWh+a0cgARkanrvoMs2oYnnERCFMiBGK2M0bHSlJ3WDGnhjdk/FRGp+2YwXkMz3w7MLBaB3nFEqCclmLU3W9M7Zy9fi6VrP8y07lSCC7fIYo1Xb2OJ2HeQVR5Q1Zpoabfe/2oxuhSb8yMdxRJU2cjxeswM8mcecg8QQX4ZtLJcgTPvCtOB6lgsHH4QaQJDAhdPeaI84/3xiUi7sV7HtCe3JpJkkxiFhlrIwNP2kinSc+8RbvX4TEug2Tc0HtWP++rs2fnAqKD4TEJI0icEmgZmZus+TL/0FZj9qnPXGNu3jXQrWVCdNX3WJi155h37pUh46dqopb2YG5jyOJ9TLY+qxoBIcpcrUXgCBgLzWgxyPcP/WO0NLeUzzWBDUGaAW0ja9Xyzt45vzE/TkuEEya0cQ5fWo5J2q467tQ8ODmYm6I5CK5n63zrO3uuZ4zk0HvR6OCNUBuzc8ZMGDaaUNuTBQgOR42ONi9UZlq/f6h8YXhV4Et7hdZURmc50VbfsY5Z2yhjGB1+wTwuzu5WW2BtIE9VGqTrAMWprhtGv6rjStKd/a+A2SGBBAwReweGyVBOJSo765DnFOoRwegMAua9s11Yz6noeudWjwGLtBGG0RWcIEQb3hs4JY2AcBzSYMb04z1JW9msibRcIXOGY7rx3nwwxkKDOETwxvfGe6Yv359tOTamvaXuDzGSWRnC6NSjhpHREVxqW8drcmR0Mf3PviXu1PLR9Fho4uVaGd3WN8Rn7aU6hVlFW5s5SR3Kqz7TZzHAc6e9al7Ta8yOC/zeOblpJheK1Jg0gLq+60JZr2wWBm4UBgzsLPm4UQXrwi5td8t8eKy8TJrHrELH8rBcAo5uCvBm3nuUjjITFjAxGhBFwJZwphYI88A8GCcVDKaCtJhJ3WShPt+6ZgY3L3sKVKsOrU/5xpMYxvxo0hzqqie6fpL57DH9ul8YWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBhYGFgYWBi4KRiwlYyNZa97HZ3dQSwirTs53BQcrHLc8hiw9ma2TspCZycrbO0POiupfGanHVsLZj3WVdd0zb654hYGFgZuOAYcrZEtVnLKazZJtUmuhYQz4uBAVVssZf821bRhrJ1FarBVUk1jA9icPfTFNxw3j8rFswuOhap7d7qY4cL7Nh92jI29O88Bm0Tb187JweO2cdmv0b6Ke8BG0xbe2nS2ClH6dzaStT3YgoWBhYFbEQasaLdFj70AMbMwurv1gxXtk2d7F6vfR8iZZ3Xboa2tbnJ4qC3F7N8nT5vS2seOlH2dYJX/3q3MrrMcNylvmlI24M5pBKeWjxbmKJ5saWQLIft22uj5NidkZiPt9DN79wW0m22n5L9nQ1f55PgTR0TVo6FsTycf+20CWqLdLeq+n/3RLfo30zxv0QKsjy0M3BowYOPZHINgI+bK6HJ0uWNKMAqExEGP2QfyEKNzcJ93cgoC7Q/knDSH78kPQUIgc2xMT3axP9qK+kVDHTOmAaiHciDaNhB98TFRa+2FWmuOepfGcRIOKBw3KJ68tjvK5sm0EFrHr/Qjb47tZ7c780lCggzCf9WTITA7B4DSDtOP5AunW6Ct7elYA8uA92h2ic8pBPZdTVz9r1sWMblnt3MnFmTD61frWzXJ27lYmCfrgr0AxR3b4mirDlvxe9pRu9oz8o96Gfy7v8723irvil8YuNVgIKcu2+U9piJSeYiB04qBY0cQBzu5g0OMztENpFWbkmJk3rX/Gi3C8S2YHLhD/47d1T/nRE2gZ7H558wx5jBlnjE6+8hV7TLaA7MqxhbALBFP+WCIOfrD3nWn7FCf/Mb/unO9NvAdwY7m1wU5EmZ2NI29CW0y7MDDU8C5c0yY9uazoe8WZGfz1PPcf2ZTYH/AaJb6WzaCtZ+gNkr+mJ99U5OWIHdJ2NuONEllMhac7BDNWvyChYGFgWvCADOWTUMR9Gh0jmZwyrT5l8ybnMrocggmDeWn+uDGPGkTFTgJZM7OAYKYJGJ7LihvpPsQuRmjYzL13LFCTi0gUZtPFKfeATuwi0PAaalCdu0+dlZf8tj6r2W9d09EC0m56wGhW3mcE+8oEN+wgbejazCFgHPlPKNlbZ3CLC0LANN3DpfM+8f+zZ3Z6fyccOfWmuDdbIDL5O5QSExDH3WopnbRpuqSs+gcFRTN0dEizgG8lCVhbzuyFmBsxkFMq/7di59ZE47hcz1fGFgYOIIBBMPgT8gBmQ4BTZx/xzecyujCDEK0aUPv1lozJzSGd+jnhkmrDKd42c2qiFk4yyonCs8YXcyqdZfvHLKJaAaYM5Urmq141+IcNnsVIFzIhyaCgQac9ya+ngeXZ+f8I/zO42KqJAREi/ANwT3iD+Bem4t3yOcMEHbCCW39XBOus7dqH8s1szBQDmd3VcHooX1udzx2hkDALGk3dXVRNjvFA1pc2lCdCDGEGozPvTPNrgp72zGnXjvWqoJ7ZTl08nVNv64XBhYGTsCA+QoDjGkuhKb+07A8d5zEKYyOOZQ5EjExiDm70Bpi9pPnGJw7RZurjOeEqkyT5kDDGaNzkCYGU4+gR/SUy8F/gRwsSPsJ5LDZMIfEn/pPm1KGB5QXaSgxlY4HSmKGpH6MlofrXs03zhiVwXEQYi5zqCIGot6Z93LAaObcHLY6AicO6Qkv5wIHFId41v4mzwgZND/31YSrnISAGTCVh3mZCw5wjHFIpbwceOu0a2ZMGrQ44SrnpfnO3naM8Df2R84xyuH5goWBhYELYyCMbjZX41MOvzMAT2V0TrrG3DA7hDkT7ZiFA/kEhBSRz33OZrpkFQ8xuvE7HCvitcc5IECrgoNf63XBBGhG4q7DVT1aJa9USz8CvFtpQb6bgLDTyo+BObPb9nawpMP7OfTRuzRtcQ5gDNyrx9HuR/Mkc5v0XPnPBYwuTC151LhTGB2Gn/lYOPqQPhfMuUcfDL62/tXxEidPpx7+Z+2Y/hWBIundK5vnCxYGFgYujIEwOvNUpP4xRAM7ldHRzMzfGLwI0Aw4fzhB+TrhFEbHGUZ5OcuMRC9EvxJKxPTSYN4o2lw9iBMhxxR8n9crT0dmLhoaDWe22HpWNsycls6092QlwV163g5bDEhLEPFNjhYVMo9IKwY0TZoxLYnW9MDWGqcTjHOrbJiauSnepgm+Fea3l9ERou7fy+n9L+wmTPXEOAhc4gUarDKaFzbXx+lIHZi4T1kS0au9+bfVjtGcR0cf98rn+YKFgYWBC2MgjM4gY0YaQwjEOYxOUREaBI15jKmsBnmb46lxri85Ib+X0dFAU57RjKXumTPjWIMoSyvuklro07XWHtLz5hQTLRgeeTP6pmUZFmYnxCR3j539goORfEYTGU9F8Vk6kuw+eyO9E4Slx2yZVzmDuBdoULTR3GvT2Snx+oX2Z/5M8M6pjI6VIN/yj9Ex/8ZZBQMWT7u7e9/5x+4/92mtYfAY/qixpv7n/B9qxzC6UQt3r4yL0Z2D8fXOwsARDITRXdp0SaMD9+0DmIMBplcDbQRRrHGumQYvBXsYXYg2QmPubQTMzTPmvUA0PM8uAUyUYRZMpKOzxaf0MijHLFTt71B5MkeEcVawIFu+mESFEGAMKUtCPKfNSp85XEyLdyoNKU415nQxZuloXCN4J0wtz2rcXo0OY7FzSrx8ax1owpm3m+HNZglhiCnDVf6PtWPamEZcIczY8wULAwsDF8ZAGB0T4v0mIRrGuRpd5vhoaYiOheTZjSKmSx58JuNf4cJ1k90xRofAZw6HhD8CzQmBZOqzTiyAEdF+PTt366vkxUSYZQ3mihD4EbJmkekNYx4DZ4hjgKCrq7rUuT/vZT5ptraMBss5py51+Nxed/VnGsTUZmC7N2kwMFpWBXG0rNrvCD9hfnsZnTxpZBxMfCuMjtfmd5RyekbzxbwxOMw7a+5quc693tOOzKTKwcu4Qpa6xBRcn63rhYGFgStiIIzO4DsUTmV0FvNiXCRt+VpYzavSNaIOwujMlYi3uHdmCnyCstNFf3X33yFGh3Ajtr5tETyGO4I9Ej1HgHnrBcSL8yz7hHp2Tlmj9ar/aNLK97KjTPUm9IyTyT1bazbJPgaWGCjvbMmA9vIsa/lqXrNtquxlKv0P9TrX9OM1cxymMuYT3MunhnMYnW9WRqdN7IQiX1r3XXsZaMspuzV2h0BbnGLS3NOOWag/LksJA/R8wcLAwsCFMRBG92mdECFGNURyx4DEczCJZB8tY7bXZUxkCA1zjLVWzFy0oEzEh9GpUhgSSTv5p6rmjWghtEG7mZwCyXd055ZHFk1bzF7nw8b8H9YJJu00uImm6lmFU8sakxU8mT/aAksJMFaOMi/fEylziPaxhc+YNMcP3+ExSQu1K4x2hdMssDdntQcsFbEW0tq1Q5D6zUy8GB1TdXDq39zeJRgdU6668gq1xg18Xo9L/KG+ZN2ostBm96wTTD2PtSOBL/OXltFYkG/5hvfEX2KnnV7d9bcwsDAQDITR7Zmjyzv5P8TozNd8ZF8XhwhkEj7bNsmjMjqmwAf3AW8brMybcBTInoCIgU2DD+3WkbLlf4vRxSQpT4E2NYZ44VlCkHS8EOOJKK4uLzinrHH22CqDubkAj8iUg5es8rrHLEazYN7JP6noJKMAAAKXSURBVJOntN/VI+yE454pkyOIa/XCbK4CzNPaDgMlDERrs4vKCJ6FqeVZjdNG2ttuPQH9aGsdXdXoaGLWRBIGlEd/TFnUlYapb9xuQ5O3UF06wTKYYwv3T2nHmnesAr4jfsHCwMLANWBgi9EhnLwPs7NINSliSrYI++lOCGYaXZxRFDlbSiEs8jU/xFMP4anLC0izTJ20waphiUcQQ3geNLjGH0ILYmcOaFx4rQ5MqIdCdb+nySpXFje7FjfCqWVVvkNl8LyC3f3t8sGT0Vo+BDZznjVdvTZ/lnnIlJnLP7wEp4SOY1phzbNe82C0m00cU5Knf1qkzQNmUJmazbVpUdKPzM+7vDa1IeZ+jNHRquGJlUJfYQ1QFss27OXKhM5ykHK6Zjoc5zmZccOI4M888hac2o7mhm2EbQz533M6w9a3V/zCwMLAEQwcYnTZIxBBqM4GcTAIoXia8o0c01MZnccm2zPfYSPnvEtir4DgVSaXZ5ij3UO8x4EBUbypcNPKykR3py5wjDgjpDCZcqQ4Fzh9pK9gJhgVZmxO8JAprjI6Zun0iborTcpkk+k8J3zNIBqdBfFZ/+kdDlXeJ9wEtJG4mGyly96TSePfDjQx+bJgLFgYWBh4JMSA+Qs7k4w7NagKqdg5dPaMrIARiRfuWB+01m7fPd0OmXoQVd98jw0PwyHL/7n1XcRmXOf2Pwlu0MUjU1kvgTbM9NCc1+wbNBkaKeBUwzTrOCcMawRx+gxtrApdNZ15Q4vVCVW8Ut+lb9xc04zXHJCYL+W7BeZEaXwzAWzrnRW/MLAwsDCwMLAwsDCwMLAwsDCwMLAwsDCwMLAwsDCwMLAwsDCwMLAwsDCwMLAwsDCwMLAwsDCwMLAwcKvDwH8BBbZ09XIC7fAAAAAASUVORK5CYII=![image.png](data:image/png;base64,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)))\n",
        "Batch size: 32\n",
        "Learning rate: 2e-5\n",
        "Epochs: 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPtfofTSkLd-"
      },
      "source": [
        "# 最適化手法の設定\n",
        "optimizer = AdamW(model.parameters(), lr=LEANING_RATE)\n",
        "\n",
        "# 訓練パートの定義\n",
        "def train(model):\n",
        "    model.train() # 訓練モードで実行\n",
        "    train_loss = 0\n",
        "    for batch in train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        logits= outputs.logits\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    return train_loss\n",
        "\n",
        "# テストパートの定義\n",
        "def validation(model):\n",
        "    model.eval()# 訓練モードをオフ\n",
        "    val_loss = 0\n",
        "    with torch.no_grad(): # 勾配を計算しない\n",
        "        for batch in validation_dataloader:\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            with torch.no_grad():\n",
        "                    outputs = model(b_input_ids, \n",
        "                                    token_type_ids=None, \n",
        "                                    attention_mask=b_input_mask,\n",
        "                                    labels=b_labels)\n",
        "            loss = outputs.loss\n",
        "            logits= outputs.logits\n",
        "            val_loss += loss.item()\n",
        "    return val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oExpwrD-kVdQ"
      },
      "source": [
        "学習に必要な関数が定義できたので、学習を行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8whsuuAM9gbo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497f21d7-d196-47a2-8604-3e15cd2bd37c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  df_performance=pd.read_csv('./%s_%s.csv' % (TERM, TYPE_INDEX), header=0)\n",
        "  print('./%s_%s.csv を 読み込みました。' % (TERM, TYPE_INDEX))\n",
        "except:\n",
        "  list_performance=[]\n",
        "  df_performance = pd.DataFrame(index=range(EPOCH), columns=['train_loss', 'valid_loss'])\n",
        "  df_performance.index.name=\"epoch\"\n",
        "  df_performance.fillna(np.nan, inplace=True)\n",
        "  df_performance.to_csv('./%s_%s.csv' % (TERM, TYPE_INDEX))\n",
        "  print('./%s_%s.csv を 作成しました。' % (TERM, TYPE_INDEX))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./S6_ForT_F.csv を 読み込みました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "l9F6dOo7Eisc",
        "outputId": "e242a064-727e-413f-ca25-adda601fa9fa"
      },
      "source": [
        "df_performance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.231791</td>\n",
              "      <td>63.185096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.228019</td>\n",
              "      <td>65.519268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   epoch  train_loss  valid_loss\n",
              "0      0    0.231791   63.185096\n",
              "1      1    0.228019   65.519268"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "c-AWRyFVkXKO",
        "outputId": "02331f53-ec52-4c2f-f24a-cd86d696c9e2"
      },
      "source": [
        "# 学習の実行\n",
        "max_epoch = EPOCH\n",
        "list_train_loss = []\n",
        "list_valid_loss = []\n",
        "import time\n",
        "start = time.time()\n",
        "epoch=0\n",
        "\n",
        "#学習途中の状態を読み込む。\n",
        "# checkpoint = torch.load(\"./model_ForT_F.tar\")\n",
        "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "# optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "# epoch = checkpoint[\"epoch\"]\n",
        "\n",
        "for epoch in range(epoch, max_epoch):\n",
        "    print(\"%s epoch\" % (epoch))\n",
        "\n",
        "    train_ = train(model)\n",
        "    list_train_loss.append(train_)\n",
        "    \n",
        "    # 学習途中の状態を保存する。 #https://pystyle.info/pytorch-save-and-load-model/\n",
        "    torch.save(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "         },\n",
        "         \"model_%s.tar\" % TYPE_INDEX,\n",
        "    )\n",
        "\n",
        "    valid_ = validation(model)\n",
        "    list_valid_loss.append(valid_)\n",
        "\n",
        "    print(df_performance.columns)\n",
        "    df_performance.loc[epoch]['train_loss']=list_train_loss[epoch]\n",
        "    df_performance.loc[epoch]['valid_loss']=list_valid_loss[epoch]\n",
        "    # df_performance['train_loss']=list_train_loss[epoch]\n",
        "    # df_performance['valid_loss']=list_val_loss[epoch]\n",
        "    df_performance.to_csv('./%s_%s.csv' % (TERM, TYPE_INDEX))\n",
        "    print(' Added to ./%s_%s.csv.' % (TERM, TYPE_INDEX))\n",
        "\n",
        "    elapsed_time = time.time() - start\n",
        "    print(\" %s epoch  :  %s [sec] → %s\" % (epoch, elapsed_time, pull_Datetime()))\n",
        "    print()\n",
        "print(\"終了時間 : %s [sec] → %s\" % (elapsed_time, pull_Datetime()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 epoch\n",
            "Index(['epoch', 'train_loss', 'valid_loss'], dtype='object')\n",
            " Added to ./S6_ForT_F.csv.\n",
            " 0 epoch  :  341.24786400794983 [sec] → 2021-11-02 00:55:21.257001+09:00\n",
            "\n",
            "1 epoch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['epoch', 'train_loss', 'valid_loss'], dtype='object')\n",
            " Added to ./S6_ForT_F.csv.\n",
            " 1 epoch  :  682.1038863658905 [sec] → 2021-11-02 01:01:02.063551+09:00\n",
            "\n",
            "2 epoch\n",
            "Index(['epoch', 'train_loss', 'valid_loss'], dtype='object')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 2 is not in range",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-d5cb07104e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_performance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mdf_performance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_train_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mdf_performance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_valid_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# df_performance['train_loss']=list_train_loss[epoch]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3491\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3493\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU8kHNOmlaEE"
      },
      "source": [
        "print('list_train_loss : ', list_train_loss)\n",
        "print('list_val_loss : ', list_valid_loss)\n",
        "\n",
        "print(test_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZi5S4PyxQ0p"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plot learning curve\n",
        "plt.figure()\n",
        "plt.plot(list(range(epoch+1)), list_train_loss, 'r-', label='train_loss')\n",
        "plt.plot(list(range(epoch+1)), list_valid_loss, 'b-', label='val_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n",
        "plt.title('%s  %s' % (TERM, TYPE_INDEX))\n",
        "\n",
        "plt.savefig('./loss_%s_%s.jpeg' % (TERM, TYPE_INDEX))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUfgmLZEka9M"
      },
      "source": [
        "#6. 検証"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r1o9FvL8F78"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uuow5vgkcjH"
      },
      "source": [
        "# 検証方法の確認（1バッチ分で計算ロジックに確認）\n",
        "\n",
        "model.eval()# 訓練モードをオフ\n",
        "for batch in validation_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    with torch.no_grad():   \n",
        "        # 学習済みモデルによる予測結果をpredsで取得     \n",
        "        preds = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0fVySmpkjux"
      },
      "source": [
        "以下の様な結果が出力されます\n",
        "この確率の様な値（厳密には、この値ををソフトマックス関数に入力すると確率になる）が大きい方のラベルをモデルは分類結果とし予測としています"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjQBUFlnkfw4"
      },
      "source": [
        "## 予測結果の確認\n",
        "print(f'出力:{preds}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4NUw7R9ktzN"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "出力:(tensor([[-5.0226,  5.0193],\n",
        "        [-5.0390,  4.9736],\n",
        "        [ 4.7941, -4.7459],\n",
        "        [-4.9395,  4.6827], device='cuda:0'),)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "238VYB-SkpcS"
      },
      "source": [
        "左からラベルの[0, 1]に対応しており、1つ目のデータであれば、右側の値が大きいのでモデルはラベル1を予測している"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpXPkkLRkzwD"
      },
      "source": [
        "# 比較しやすい様にpd.dataframeへ整形\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n",
        "logits_df = pd.DataFrame(preds[0].cpu().numpy(), columns=['logit_0', 'logit_1'])\n",
        "## np.argmaxで大き方の値を取得\n",
        "pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n",
        "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
        "\n",
        "accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
        "\n",
        "accuracy_df.head()\n",
        "\n",
        "accuracy_df.to_csv('./%s.csv' % TYPE_INDEX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_DmAbeWHhlt"
      },
      "source": [
        "accuracy_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ym-Osozs7vV"
      },
      "source": [
        "accuracy_df['answer'] = (accuracy_df['pred_label'] == accuracy_df['true_label'])\n",
        "list_answer=accuracy_df['answer'].to_list()\n",
        "count_true=list_answer.count(True)\n",
        "print(list_answer)\n",
        "print(count_true)\n",
        "print('accuracy : ',  float(count_true / len(list_answer))*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjh6cRYgig5D"
      },
      "source": [
        "pred_df.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfBW35B6k2rC"
      },
      "source": [
        "上記の様に予測ラベルと正解ラベルを取得して、dataframeへ保存することができました\n",
        "\n",
        "あとは、シンプルに正解率を計算するなり、sklearnを用いて混合行列を作成するなり、好きな様に分類モデルの評価を行うことができる。"
      ]
    }
  ]
}