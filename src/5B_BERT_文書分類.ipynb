{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "5B_BERT_文書分類.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "959bb46a3f0f48899cf7fe80c5648317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fd2f68310d047f68e208b03ffc5ec4d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6415e1e65b4a4d37b2cbbe7837fa65c5",
              "IPY_MODEL_a0be63c23c5a4ea180927552b67bbf1e",
              "IPY_MODEL_0998b9fc28b14989b18427bf44bd53f8"
            ]
          }
        },
        "4fd2f68310d047f68e208b03ffc5ec4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6415e1e65b4a4d37b2cbbe7837fa65c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c307e26c44524f70bdd8b92a9fbfddfe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8d90b496c84418bb15cd0c79e254cf8"
          }
        },
        "a0be63c23c5a4ea180927552b67bbf1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a6125c74db3e432185646a506a3b2c31",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9999,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9999,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fb3d5e68af84b068b2fa95907b70076"
          }
        },
        "0998b9fc28b14989b18427bf44bd53f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce3cb72a36814e48807b5ea94994bd8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9999/9999 [00:02&lt;00:00, 4130.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_493ba478329e419eb9a3eff4a6763651"
          }
        },
        "c307e26c44524f70bdd8b92a9fbfddfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8d90b496c84418bb15cd0c79e254cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6125c74db3e432185646a506a3b2c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fb3d5e68af84b068b2fa95907b70076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce3cb72a36814e48807b5ea94994bd8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "493ba478329e419eb9a3eff4a6763651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cf5a66dfde04fc8af665f721b6c661f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29eefc1fd2b24cc796bb4539cd75fcb9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e9c174aee3849bdb8c799eca8983e6e",
              "IPY_MODEL_2a372907032e4aacba98f98df85f4e3a",
              "IPY_MODEL_0a169501c5dc4eb696e31873d4874e12"
            ]
          }
        },
        "29eefc1fd2b24cc796bb4539cd75fcb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e9c174aee3849bdb8c799eca8983e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f0a9505afb64f60abc549b512ecaf73",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f12515ec2b264210baead497b9df15d1"
          }
        },
        "2a372907032e4aacba98f98df85f4e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b6f1c25f6ef470182751938ac92300d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9999,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9999,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92c7ec2d045f46fe9128a372da9e8cb8"
          }
        },
        "0a169501c5dc4eb696e31873d4874e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b75f6c06bc44d29b627491b2caaf923",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9999/9999 [00:05&lt;00:00, 1678.54it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61fea5ca85a14344adfbb89059ec5d2c"
          }
        },
        "6f0a9505afb64f60abc549b512ecaf73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f12515ec2b264210baead497b9df15d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b6f1c25f6ef470182751938ac92300d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92c7ec2d045f46fe9128a372da9e8cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b75f6c06bc44d29b627491b2caaf923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61fea5ca85a14344adfbb89059ec5d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sj0054pe/MBTI_Estim/blob/master/src/5B_BERT_%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C6N93XpYPLr"
      },
      "source": [
        "#<center>BERT Twitter 文書分類 </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwHdrkqu1FzS"
      },
      "source": [
        "###<center>参考サイト</center>\n",
        "\n",
        "###<center>https://qiita.com/takubb/items/fd972f0ac3dba909c293</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA7agruVYgR5"
      },
      "source": [
        "1. 準備（ライブラリのインストール）\n",
        "2. データセットの準備\n",
        "3. データの前処理（BERTが受けとれる形式にデータを整形）\n",
        "4. 学習済みモデルのロード\n",
        "5. 訓練（Pre-trainedモデルのファインチューニング）\n",
        "6. 検証"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIu7ycEEYusQ"
      },
      "source": [
        "#0. 作業環境の準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDXDLQ87173r"
      },
      "source": [
        "##0.1. google driveのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umfbnIKHK5tx",
        "outputId": "ed3b70ea-c74f-4859-d288-462c0e7ccedc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_c9RJLU91_UN"
      },
      "source": [
        "##0.2. カレントディレクトリへ移動"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "242T3dKmYbmQ",
        "outputId": "a636c358-7295-4b75-a011-5e3598b07efc"
      },
      "source": [
        "%cd /content/drive/MyDrive/研究室/研究_M2/src"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1OWWQmFsr-0HoCVHJBaVtdmaZ4m43kkOk/研究_M2/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjpE_QDS2Ca9"
      },
      "source": [
        "##0.3. GPUへ接続"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A6tMRaPYtwe"
      },
      "source": [
        "import torch\n",
        "# GPUが使えれば利用する設定\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75NJeaYt2FPa"
      },
      "source": [
        "##0.4. 現在時刻の取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1Gxsj0s0-Ul"
      },
      "source": [
        "import datetime\n",
        "import pytz\n",
        "\n",
        "def pull_Datetime():\n",
        "  DATETIME_now = datetime.datetime.now(pytz.timezone('Asia/Tokyo'))\n",
        "  #print(DATETIME_now)\n",
        "\n",
        "  return DATETIME_now"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA23X1OP2JDM"
      },
      "source": [
        "##0.5. 分類モデルの性格指標を指定\n",
        "\n",
        "この指標をもとに、2クラス分類を行う。\n",
        "\n",
        "E or I なら\n",
        "EI指標の分類器を作成する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0mHOn1leOR4"
      },
      "source": [
        "#TYPE_INDEX='EorI_E'\n",
        "#TYPE_INDEX='NorS_N'\n",
        "#TYPE_INDEX='ForT_F'\n",
        "TYPE_INDEX='JorP_J'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ktlj_ar2hF0"
      },
      "source": [
        "##0.6. 学習するデータセットの指定\n",
        "\n",
        "ツイッターの各投稿に、MBTIの16性格がラベリングされている。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht6JZsf0J8AC"
      },
      "source": [
        "#INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S1_forBERT_2021-10-01.csv'\n",
        "#INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S2_forBERT_2021-10-03.csv'\n",
        "#INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S3_forBERT_2021-10-03.csv'\n",
        "#INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S4_forBERT_2021-10-15.csv'\n",
        "INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S5_forBERT_2021-10-23.csv'\n",
        "\n",
        "#INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S7_forBERT_2021-11-08_U10sentences.csv' #実質S6\n",
        "\n",
        "#INPUT_CSV_v6='./Assets/Assets_Output/Tweet_Datasets/v6S7_forBERT_2021-11-09_U20R10000.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeqhMagu6kL3"
      },
      "source": [
        "##0.7 学習パラメータを指定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF-q9msi6iyP"
      },
      "source": [
        "LEANING_RATE=2e-5\n",
        "BATCH_SIZE=64\n",
        "EPOCH=20"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pIIrxzUR9y-"
      },
      "source": [
        "SEASONS='S5'\n",
        "HIGHER = 10\n",
        "RAFFLE=10000\n",
        "\n",
        "\n",
        "#SWITCH_CONTINUE ='on'\n",
        "SWITCH_CONTINUE ='off'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CItkmu4p2IM",
        "outputId": "e55b6d51-f829-4764-9950-c64f5c73ba06"
      },
      "source": [
        "TERM='%s_L%s_B%s_E%s_H%s_R%s' % (SEASONS, LEANING_RATE, BATCH_SIZE, EPOCH, HIGHER, RAFFLE)\n",
        "\n",
        "print(TERM)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S5_L2e-05_B64_E20_H10_R10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YuZBAGNKS37"
      },
      "source": [
        "#1. 準備 (ライブラリのインストール)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmerZUNiYzdG"
      },
      "source": [
        "Hugging Face Library 'Transformer' のダウンロード\n",
        "\n",
        "* transformers\n",
        "* 最新のNLPモデルを利用できるライブラリ\n",
        "* BERTの他にもGPT-2, RoBERTa, XLM, DistilBert, XLNet, T5, CTRL...などの最新モデルや100言語以上の学習済みモデル（Pre-trained model）を利用可能"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvUfHhiHYzJR",
        "outputId": "3b693f92-05b0-468a-da9c-a61ba5182db6"
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3\n",
        "\n",
        "#参考サイト (https://qiita.com/takubb/items/fd972f0ac3dba909c293) では欠けているライブラリ\n",
        "!pip install fugashi\n",
        "!pip install ipadic"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "aptitude is already the newest version (0.8.10-6ubuntu1).\n",
            "swig is already the newest version (3.0.12-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.9)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.16)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "mecab is already installed at the requested version (0.996-5)\n",
            "libmecab-dev is already installed at the requested version (0.996-5)\n",
            "mecab-ipadic-utf8 is already installed at the requested version (2.7.0-20070801+main-1)\n",
            "git is already installed at the requested version (1:2.17.1-1ubuntu0.9)\n",
            "make is already installed at the requested version (4.1-9.1ubuntu1)\n",
            "curl is already installed at the requested version (7.58.0-2ubuntu3.16)\n",
            "xz-utils is already installed at the requested version (5.2.2-1.3)\n",
            "file is already installed at the requested version (1:5.32-2ubuntu0.4)\n",
            "No packages will be installed, upgraded, or removed.\n",
            "0 packages upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 0 B of archives. After unpacking 0 B will be used.\n",
            "                            \n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: fugashi in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied: ipadic in /usr/local/lib/python3.7/dist-packages (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJtypZI6Y6kx"
      },
      "source": [
        "#2. データセットの準備\n",
        "\n",
        "##2.1.準備したツイートデータをダウンロードする。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "xxb7wakmY46L",
        "outputId": "07f50f16-b36d-421e-f926-16e2bc953fd3"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('%s' % INPUT_CSV_v6, engine='python')\n",
        "\n",
        "# データの確認\n",
        "print(f'データサイズ： {df.shape}')\n",
        "\n",
        "df[['text', 'tweet_time', 'MBTI_Type','label_EorI','label_NorS','label_ForT','label_JorP']].sample(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "データサイズ： (10003, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_time</th>\n",
              "      <th>MBTI_Type</th>\n",
              "      <th>label_EorI</th>\n",
              "      <th>label_NorS</th>\n",
              "      <th>label_ForT</th>\n",
              "      <th>label_JorP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>@xxxvis @tia_ship10 (´・ω・`)💦</td>\n",
              "      <td>2017-06-20 23:17:40+00:00</td>\n",
              "      <td>INFP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2677</th>\n",
              "      <td>人が多い時を避けて帰省する策士でございます笑</td>\n",
              "      <td>2017-04-28 20:06:10+00:00</td>\n",
              "      <td>ESFP</td>\n",
              "      <td>E</td>\n",
              "      <td>S</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9146</th>\n",
              "      <td>キズナアイとミライアカリとのじゃロリ狐娘おじさんが勝手に対立させられてて笑う。</td>\n",
              "      <td>2017-12-21 03:15:45+00:00</td>\n",
              "      <td>ISFP</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8168</th>\n",
              "      <td>飯食って帰ろうかな…いや寝る時間減るやろバカタレ…</td>\n",
              "      <td>2017-12-17 02:25:12+00:00</td>\n",
              "      <td>ISFP</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>MGS3の話をしたら…… スネークマッチとマカロフとSAAが欲しくなってしまった今日この頃…...</td>\n",
              "      <td>2017-12-25 13:08:52+00:00</td>\n",
              "      <td>ISTJ</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>T</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5648</th>\n",
              "      <td>許せない誤訳②～My Heart Will Go On</td>\n",
              "      <td>2017-10-09 11:26:00+00:00</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1402</th>\n",
              "      <td>個人的にスーパーロボット風味なゴルドリーオは嫌いじゃ無いけど、アルディラッドカンバーの玄人向...</td>\n",
              "      <td>2017-09-25 14:03:37+00:00</td>\n",
              "      <td>INFP</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9524</th>\n",
              "      <td>ノースポート先週行ったけど原因は何なんだろう</td>\n",
              "      <td>2017-11-10 04:09:48+00:00</td>\n",
              "      <td>ISFJ</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>F</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1240</th>\n",
              "      <td>@5ayakachan_bot 年始は平日の方が休み取りやすそう9,10辺りとか</td>\n",
              "      <td>2017-12-23 14:52:54+00:00</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1289</th>\n",
              "      <td>スポーツ時事とか100m走9.98以外何があるんや？</td>\n",
              "      <td>2017-09-13 12:08:09+00:00</td>\n",
              "      <td>ISFP</td>\n",
              "      <td>I</td>\n",
              "      <td>S</td>\n",
              "      <td>F</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ... label_JorP\n",
              "786                        @xxxvis @tia_ship10 (´・ω・`)💦  ...          P\n",
              "2677                             人が多い時を避けて帰省する策士でございます笑  ...          P\n",
              "9146            キズナアイとミライアカリとのじゃロリ狐娘おじさんが勝手に対立させられてて笑う。  ...          P\n",
              "8168                          飯食って帰ろうかな…いや寝る時間減るやろバカタレ…  ...          P\n",
              "385   MGS3の話をしたら…… スネークマッチとマカロフとSAAが欲しくなってしまった今日この頃…...  ...          J\n",
              "5648                        許せない誤訳②～My Heart Will Go On  ...          J\n",
              "1402  個人的にスーパーロボット風味なゴルドリーオは嫌いじゃ無いけど、アルディラッドカンバーの玄人向...  ...          P\n",
              "9524                             ノースポート先週行ったけど原因は何なんだろう  ...          J\n",
              "1240           @5ayakachan_bot 年始は平日の方が休み取りやすそう9,10辺りとか  ...          J\n",
              "1289                         スポーツ時事とか100m走9.98以外何があるんや？  ...          P\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeUswwipVfUJ",
        "outputId": "c96c0e11-1e2b-44fb-b1d0-a515dbb6fd04"
      },
      "source": [
        "df.dropna(how='any', axis=0, inplace=True)\n",
        "print(f'データサイズ： {df.shape}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "データサイズ： (9999, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdmhA807JGmJ"
      },
      "source": [
        "##2.2. 性格指標のone-hot化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "A8Sod6gSJDIK",
        "outputId": "b6f8c768-bc5c-4003-d39b-0f1d344745c3"
      },
      "source": [
        "df=pd.get_dummies(df, columns=[\"label_EorI\", \"label_NorS\", \"label_ForT\", \"label_JorP\"], sparse=True)\n",
        "df[['text', 'tweet_time', 'MBTI_Type','label_EorI_E','label_NorS_N','label_ForT_F','label_JorP_J']]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_time</th>\n",
              "      <th>MBTI_Type</th>\n",
              "      <th>label_EorI_E</th>\n",
              "      <th>label_NorS_N</th>\n",
              "      <th>label_ForT_F</th>\n",
              "      <th>label_JorP_J</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>とても久しぶりな動画製作中... 　覚えたことは早速使いたい感が編集TLに出てる</td>\n",
              "      <td>2017-11-25 15:53:33+00:00</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>道中大破の撤退を減らすには艦隊司令部を置けばいいんだろうけどそうするとどう考えてもボスで優勢...</td>\n",
              "      <td>2017-12-04 14:38:25+00:00</td>\n",
              "      <td>ISTJ</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#セレスティア・ルーデンベルク生誕祭2017 誕生日おめでとうございます！！ ドッヒャーは未...</td>\n",
              "      <td>2017-11-22 15:11:32+00:00</td>\n",
              "      <td>INFP</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>今回は無かったですけど、タイミング次第であるみたいです😁</td>\n",
              "      <td>2017-12-24 02:17:13+00:00</td>\n",
              "      <td>INFP</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>最後のアレで持ってかれたw直虎面白かった(そして泣いた)直政の元服における口上も最高でしたヽ...</td>\n",
              "      <td>2017-12-17 10:00:02+00:00</td>\n",
              "      <td>ISTP</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>今日初めて大学生相手に研修をやりましたが、とてもしんどかった。</td>\n",
              "      <td>2017-02-20 07:50:57+00:00</td>\n",
              "      <td>ENTP</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>HKT48の最高かよにハマってしまった。。。</td>\n",
              "      <td>2017-05-20 15:05:43+00:00</td>\n",
              "      <td>INTP</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>キングハサンは本人のカード性能理解しないと難しいなぁ</td>\n",
              "      <td>2017-12-29 17:23:09+00:00</td>\n",
              "      <td>INTP</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10001</th>\n",
              "      <td>まぁ僕は両方とNFSPBもハンコン買いますが(バイト代消滅不可避) あとgtsport はナ...</td>\n",
              "      <td>2017-10-19 12:50:19+00:00</td>\n",
              "      <td>INFP</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10002</th>\n",
              "      <td>ですです! 覚醒結晶が30魔石で各停はおいしいですもんねᏊˊ•ﻌ•ˋᏊ 欲を言えばルーンの方...</td>\n",
              "      <td>2017-11-27 14:07:33+00:00</td>\n",
              "      <td>INFJ</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9999 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  ... label_JorP_J\n",
              "0               とても久しぶりな動画製作中... 　覚えたことは早速使いたい感が編集TLに出てる  ...            1\n",
              "1      道中大破の撤退を減らすには艦隊司令部を置けばいいんだろうけどそうするとどう考えてもボスで優勢...  ...            1\n",
              "2      #セレスティア・ルーデンベルク生誕祭2017 誕生日おめでとうございます！！ ドッヒャーは未...  ...            0\n",
              "3                           今回は無かったですけど、タイミング次第であるみたいです😁  ...            0\n",
              "4      最後のアレで持ってかれたw直虎面白かった(そして泣いた)直政の元服における口上も最高でしたヽ...  ...            0\n",
              "...                                                  ...  ...          ...\n",
              "9998                     今日初めて大学生相手に研修をやりましたが、とてもしんどかった。  ...            0\n",
              "9999                              HKT48の最高かよにハマってしまった。。。  ...            0\n",
              "10000                         キングハサンは本人のカード性能理解しないと難しいなぁ  ...            0\n",
              "10001  まぁ僕は両方とNFSPBもハンコン買いますが(バイト代消滅不可避) あとgtsport はナ...  ...            0\n",
              "10002  ですです! 覚醒結晶が30魔石で各停はおいしいですもんねᏊˊ•ﻌ•ˋᏊ 欲を言えばルーンの方...  ...            1\n",
              "\n",
              "[9999 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RLwGStUi5Fu"
      },
      "source": [
        "sentences= df['text'].values #sentences = df.sentence.values\n",
        "labels= df['label_%s' % TYPE_INDEX].values #labels = df.label.values"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMl0WC3MOECX",
        "outputId": "41cade34-2f74-466a-8a67-e6fc38fd459a"
      },
      "source": [
        "labels "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...]\n",
              "Fill: 0\n",
              "IntIndex\n",
              "Indices: array([   0,    1,    6, ..., 9991, 9993, 9998], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUtOVe9SuJqt",
        "outputId": "7b83e6e3-80cf-415a-8ab3-4c816cf8cc22"
      },
      "source": [
        "print(len(sentences))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21UWv4KfjCB3"
      },
      "source": [
        "#3. データの前処理（BERTが受けとれる形式にデータを整形）\n",
        "\n",
        "BERTでは基本的に学習済みモデルを利用する為、そのモデルが読み込めるフォーマットにデータを変換する必要があります\n",
        "具体的には、以下の4つ手続きが必要になります\n",
        "\n",
        "1. BERT Tokenizerを用いて単語分割・IDへ変換\n",
        ">* 学習済みモデルの作成時と同じtokenizer（形態素解析器）を利用する必要がある\n",
        ">* 日本語ではMecabやJuman++を利用されることが多い\n",
        "\n",
        "2. Special tokenの追加\n",
        ">* 文章の最後に[SEP]という単語する\n",
        ">* 文章のはじめに[CLS]という単語を追加する（分類問題に利用される）\n",
        "3. 文章の長さの固定\n",
        ">* BERTでは全ての文書の長さ（単語の数）を同じにする必要がある（1文章あたりの最大の単語数は512単語）\n",
        ">* そこで、Padding/Truncatingを用いて固定長に変換する\n",
        ">* Paddingとは、指定した長さに満たない文章を[Pad]という意味を持たない単語の埋める処理\n",
        ">* Truncatingとは、指定した長さを超える単語を切り捨てること\n",
        "4. Attention mask arrayの作成\n",
        ">* [Padding]を0、それ以外のTokenを1とした配列\n",
        ">* 一見ややこししそう見えますが、どれもTransformerのライブラリでサポートされているので、簡単に実行できます\n",
        "\n",
        "また、以下のイメージも参考にモデルの全体像と照らし合わせながら前処理内容をみるとイメージが沸きやすいかもしれません"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGL6B-xKjI3M"
      },
      "source": [
        "##3.1. BERT Tokenizerを用いて単語分割・IDへ変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w1Z3BvUjF77",
        "outputId": "ccc3e900-b460-4fdd-a6dc-d9e81f9294b1"
      },
      "source": [
        "## Tokenizerの準備\n",
        "from transformers import BertJapaneseTokenizer\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "\n",
        "#念の為、確認\n",
        "## テスト実行\n",
        "# 元文章\n",
        "print(' Original: ', sentences[0])\n",
        "# Tokenizer\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "# Token-id\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  とても久しぶりな動画製作中... 　覚えたことは早速使いたい感が編集TLに出てる\n",
            "Tokenized:  ['とても', '久', '##し', '##ぶり', 'な', '動画', '製作', '中', '...', '覚え', 'た', 'こと', 'は', '早速', '使い', 'たい', '感', 'が', '編集', 'T', '##L', 'に', '出', 'てる']\n",
            "Token IDs:  [8567, 1658, 28454, 14657, 18, 4884, 1300, 51, 3215, 8806, 10, 45, 9, 21966, 3276, 1549, 832, 14, 2028, 260, 28743, 7, 71, 7134]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igADsm2KjVcE"
      },
      "source": [
        "##3.2. 次に文章の長さを固定する為に、文章あたりの最大単語数を確認します\n",
        "\n",
        "ここでは、以下の方法で最大単語数を確認していますが、最大単語数は決め打ちで設定することも可能です"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6CO0d-HCDja"
      },
      "source": [
        "# print(sentences[15806])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "959bb46a3f0f48899cf7fe80c5648317",
            "4fd2f68310d047f68e208b03ffc5ec4d",
            "6415e1e65b4a4d37b2cbbe7837fa65c5",
            "a0be63c23c5a4ea180927552b67bbf1e",
            "0998b9fc28b14989b18427bf44bd53f8",
            "c307e26c44524f70bdd8b92a9fbfddfe",
            "b8d90b496c84418bb15cd0c79e254cf8",
            "a6125c74db3e432185646a506a3b2c31",
            "5fb3d5e68af84b068b2fa95907b70076",
            "ce3cb72a36814e48807b5ea94994bd8c",
            "493ba478329e419eb9a3eff4a6763651"
          ]
        },
        "id": "wqzm2jSYjYtx",
        "outputId": "883bc4e1-e4ee-462e-8070-8e5fca28aec6"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# 最大単語数の確認\n",
        "max_len = []\n",
        "# 1文づつ処理\n",
        "len_sentences = len(sentences)\n",
        "for sent in tqdm(sentences):\n",
        "    # Tokenizeで分割\n",
        "    token_words = tokenizer.tokenize(sent)\n",
        "    # 文章数を取得してリストへ格納\n",
        "    max_len.append(len(token_words))\n",
        "# 最大の値を確認\n",
        "len_max=max(max_len)\n",
        "#len_q0, len_q25, len_q50, len_q75, len_q100=np.percentile(max_len,  [0, 25, 50, 75, 100])\n",
        "#len_q75=int(len_q75)\n",
        "print('最大単語数: ', max(max_len))\n",
        "print('上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "959bb46a3f0f48899cf7fe80c5648317",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9999 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最大単語数:  129\n",
            "上記の最大単語数にSpecial token（[CLS], [SEP]）の+2をした値が最大単語数\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Iy684SijdEO"
      },
      "source": [
        "##3.3. Tokenizerと最大単語数の確認がとれたので、全ての文章に一括して処理を行います\n",
        "\n",
        "tokenizer.encode_plusを利用するとまとめて処理が行えます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "3cf5a66dfde04fc8af665f721b6c661f",
            "29eefc1fd2b24cc796bb4539cd75fcb9",
            "7e9c174aee3849bdb8c799eca8983e6e",
            "2a372907032e4aacba98f98df85f4e3a",
            "0a169501c5dc4eb696e31873d4874e12",
            "6f0a9505afb64f60abc549b512ecaf73",
            "f12515ec2b264210baead497b9df15d1",
            "2b6f1c25f6ef470182751938ac92300d",
            "92c7ec2d045f46fe9128a372da9e8cb8",
            "8b75f6c06bc44d29b627491b2caaf923",
            "61fea5ca85a14344adfbb89059ec5d2c"
          ]
        },
        "id": "sWPRjjZIjfRC",
        "outputId": "90147dd4-c7bf-4d82-8831-5d8fd01119d8"
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# 1文づつ処理\n",
        "for sent in tqdm(sentences):\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True, # Special Tokenの追加\n",
        "                        max_length = len_max,        # 文章の長さを固定（Padding/Trancatinating）#mayo\n",
        "                        pad_to_max_length = True,# PADDINGで埋める\n",
        "                        return_attention_mask = True,   # Attention maksの作成\n",
        "                        return_tensors = 'pt',     #  Pytorch tensorsで返す\n",
        "                   )\n",
        "\n",
        "    # 単語IDを取得    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # Attention　maskの取得\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# リストに入ったtensorを縦方向（dim=0）へ結合\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cf5a66dfde04fc8af665f721b6c661f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/9999 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvi8VKqgIkpj"
      },
      "source": [
        "##labelをtensor型に変換\n",
        "\n",
        "labelはpd.get_dummiesでone-hotにしてます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4ZMdlFhIanB"
      },
      "source": [
        "# tenosor型に変換\n",
        "labels = torch.tensor(labels)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdZuAV8oJHk9"
      },
      "source": [
        "## BERTの前処理が正常に実行されたか確認\n",
        "\n",
        "前処理は、\n",
        "\n",
        "Special tokenの追加、文章の長さの固定、Attention mask arrayの作成\n",
        "\n",
        "である。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LelL1aVJGqT",
        "outputId": "c52050ee-4db7-4958-b252-c3a6b889a38f"
      },
      "source": [
        "# 確認\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  とても久しぶりな動画製作中... 　覚えたことは早速使いたい感が編集TLに出てる\n",
            "Token IDs: tensor([    2,  8567,  1658, 28454, 14657,    18,  4884,  1300,    51,  3215,\n",
            "         8806,    10,    45,     9, 21966,  3276,  1549,   832,    14,  2028,\n",
            "          260, 28743,     7,    71,  7134,     3,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K1TIhOUjiAR"
      },
      "source": [
        "1つ目の文章の前処理結果です\n",
        "\n",
        "元々、日本語テキストだった文章がID化されています\n",
        "\n",
        "Token IDsの最初に単語IDはSpecial tokenの[CLS]を表し、後半の0埋めが[Pad]を示しています\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Original:  旧式Macで禁断のパワーアップ！最新PCやソフトを一挙にチェック\n",
        "Token IDs: tensor([    2, 18718,  8653,    12,  1763, 29135,     5, 20734,   679,  6215,\n",
        "         3794,    49,  1604,    11, 24598,     7,  9398,     3,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
        "            0,     0,     0,     0,     0,     0,     0])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF-tpHIxjnbX"
      },
      "source": [
        "##3.5. データローダの適用とデータの分割\n",
        "\n",
        "ここまでで、前処理が完了したので、90%を訓練データ、10％をテストデータに分割して、pytorchで学習を行う為に、データローダーへ変換しておきます\n",
        "\n",
        "データローダーの説明は、pytorchの基本的な操作なので本記事では割愛します（簡単に言うと、データをバッチごとに分割して、学習を上手くやってくれるデータ型です）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5knJ5xITjikd",
        "outputId": "d7b6542b-218b-4b02-c626-e78668da0e4f"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# データセットクラスの作成\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# 90%地点のIDを取得\n",
        "# train_size = int(0.9 * len(dataset))\n",
        "# val_size = len(dataset) - train_size\n",
        "#train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# データセットを分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_dataset, val_dataset  = train_test_split(dataset, train_size=(0.7+0.1))\n",
        "val_dataset, test_dataset  = train_test_split(val_dataset, train_size=(0.7+0.1))\n",
        "\n",
        "print('訓練データ数：{}'.format(len(train_dataset)))\n",
        "print('検証データ数:　{} '.format(len(val_dataset )))\n",
        "print('テストデータ数:　{} '.format(len(test_dataset)))\n",
        "\n",
        "# データローダーの作成\n",
        "batch_size = BATCH_SIZE\n",
        "\n",
        "# 訓練データローダー\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), # ランダムにデータを取得してバッチ化\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# 検証データローダー\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), # 順番にデータを取得してバッチ化\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "\n",
        "# 検証データローダー\n",
        "test_dataloader = DataLoader(\n",
        "            test_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), # 順番にデータを取得してバッチ化\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "訓練データ数：7999\n",
            "検証データ数:　1599 \n",
            "テストデータ数:　401 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uuhm0mxWjvRK"
      },
      "source": [
        "#4. 学習済みモデルのロード\n",
        "\n",
        "huggingface transformerのBERTファインチューニングでは以下のタスクをサポートしています\n",
        "全てBERT Pre-trainedモデルをベースとして学習し、出力層のみそれぞれのタスクに適した構成になっています\n",
        "\n",
        "* BertModel\n",
        "* BertForPreTraining\n",
        "*   BertForMaskedLM\n",
        "*   BertForNextSentencePrediction\n",
        "*   BertForSequenceClassification\n",
        "*   BertForTokenClassification\n",
        "* BertForQuestionAnswering\n",
        "\n",
        "公式ドキュメント."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzI8Fkkmj4UR"
      },
      "source": [
        "## BertForSequenceClassification\n",
        "\n",
        "今回は2クラス分類問題なのでBertForSequenceClassificationを利用します\n",
        "\n",
        "BertForSequenceClassificationは**「BERT学習済みモデルの最後の層に分類用のレイヤー追加したネットワーク構成」**です\n",
        "\n",
        "データを入力することで、学習済みモデル全体と未学習部分の分類機レイヤーの学習が行われます\n",
        "\n",
        "デフォルトでは、モデル全体のパラメーターがファインチューニングされますが、学習させるレイヤーの設定変更も可能です\n",
        "\n",
        "モデルロード時にnum_labelsを変更することで多クラス分類問題へも対応できます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2dsv2NnkIoA",
        "outputId": "e37b2bdb-f78e-4fd0-9a94-f663b5a1ea4c"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# BertForSequenceClassification 学習済みモデルのロード\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"cl-tohoku/bert-base-japanese-whole-word-masking\", # 日本語Pre trainedモデルの指定\n",
        "    num_labels = 2, # ラベル数（今回はBinayなので2、数値を増やせばマルチラベルも対応可）\n",
        "    output_attentions = False, # アテンションベクトルを出力するか\n",
        "    output_hidden_states = False, # 隠れ層を出力するか\n",
        ")\n",
        "\n",
        "# モデルをGPUへ転送\n",
        "model.cuda()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxggBnjMkMF6"
      },
      "source": [
        "学習済みモデルのロードが完了しました\n",
        "\n",
        "次にこのモデルを手元のデータに合うようにファインチューニングを行います"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrgUL9rIkMmR"
      },
      "source": [
        "#5. 訓練（Pre-trainedモデルのファインチューニング）\n",
        "\n",
        "モデルのファインチューニングは通常のニューラルネットワークの学習と同様で、損失関数と最適化手法（Optimizer）を指定して、学習ループ（任意のバッチサイズとエポックを指定）を回します\n",
        "\n",
        "BERTでは損失関数はすでに定義されているので、ハイパーパラメーターとして、最適化手法とバッチサイズをエポック数だけ指定します\n",
        "\n",
        "ここでは、論文（BERT paper, Appendix A.3）に従って、最適化関数はAdamW（Adam Weight Decay fix）を利用し、ハイパーパラメーターは下記のように設定します\n",
        "\n",
        "Batch size: 32\n",
        "Learning rate: 2e-5\n",
        "Epochs: 4\n",
        "\n",
        "https://qiita.com/takubb/items/fd972f0ac3dba909c293"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPtfofTSkLd-"
      },
      "source": [
        "# 最適化手法の設定\n",
        "optimizer = AdamW(model.parameters(), lr=LEANING_RATE)\n",
        "\n",
        "# 訓練パートの定義\n",
        "def train(model):\n",
        "    model.train() # 訓練モードで実行\n",
        "    train_loss = 0\n",
        "    count_batch=0\n",
        "    for batch in train_dataloader:# train_dataloaderはword_id, mask, labelを出力する点に注意\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        logits= outputs.logits\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        count_batch+=1\n",
        "    train_loss = train_loss / count_batch #https://yoshinashigoto-blog.herokuapp.com/detail/30/\n",
        "    return train_loss\n",
        "\n",
        "# テストパートの定義\n",
        "def validation(model):\n",
        "    model.eval()# 訓練モードをオフ\n",
        "    valid_loss = 0\n",
        "    count_batch=0\n",
        "    with torch.no_grad(): # 勾配を計算しない\n",
        "        for batch in validation_dataloader:\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "            with torch.no_grad():\n",
        "                    outputs_valid = model(b_input_ids, \n",
        "                                    token_type_ids=None, \n",
        "                                    attention_mask=b_input_mask,\n",
        "                                    labels=b_labels)\n",
        "                    loss = outputs_valid.loss\n",
        "                    logits= outputs_valid.logits\n",
        "            valid_loss += loss.item()\n",
        "            count_batch+=1\n",
        "    valid_loss= valid_loss/count_batch\n",
        "    return valid_loss"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oExpwrD-kVdQ"
      },
      "source": [
        "学習に必要な関数が定義できたので、学習を行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8whsuuAM9gbo",
        "outputId": "fd2df0da-0799-43b0-9ca3-fd77170633e4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  df_performance=pd.read_csv('./%s_%s.csv' % (TERM, TYPE_INDEX), header=0)\n",
        "  print('./%s_%s.csv を 読み込みました。' % (TERM, TYPE_INDEX))\n",
        "except:\n",
        "  list_performance=[]\n",
        "  df_performance = pd.DataFrame(index=range(EPOCH), columns=['train_loss', 'valid_loss'])\n",
        "  df_performance.index.name=\"epoch\"\n",
        "  df_performance.fillna(np.nan, inplace=True)\n",
        "  df_performance.to_csv('./%s_%s.csv' % (TERM, TYPE_INDEX))\n",
        "  print('./%s_%s.csv を 作成しました。' % (TERM, TYPE_INDEX))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./S5_L2e-05_B64_E20_H10_R10000_JorP_J.csv を 読み込みました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "l9F6dOo7Eisc",
        "outputId": "037073f7-4eab-4007-d182-a6b5a56630e3"
      },
      "source": [
        "df_performance"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epoch  train_loss  valid_loss\n",
              "0       0         NaN         NaN\n",
              "1       1         NaN         NaN\n",
              "2       2         NaN         NaN\n",
              "3       3         NaN         NaN\n",
              "4       4         NaN         NaN\n",
              "5       5         NaN         NaN\n",
              "6       6         NaN         NaN\n",
              "7       7         NaN         NaN\n",
              "8       8         NaN         NaN\n",
              "9       9         NaN         NaN\n",
              "10     10         NaN         NaN\n",
              "11     11         NaN         NaN\n",
              "12     12         NaN         NaN\n",
              "13     13         NaN         NaN\n",
              "14     14         NaN         NaN\n",
              "15     15         NaN         NaN\n",
              "16     16         NaN         NaN\n",
              "17     17         NaN         NaN\n",
              "18     18         NaN         NaN\n",
              "19     19         NaN         NaN"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-AWRyFVkXKO",
        "outputId": "4ac4fd95-846b-47ad-8c45-061462aa51ea"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "# 学習の実行\n",
        "max_epoch = EPOCH\n",
        "list_train_loss = []\n",
        "list_valid_loss = []\n",
        "epoch=0\n",
        "\n",
        "#学習途中の状態を読み込む。\n",
        "if SWITCH_CONTINUE=='on':\n",
        "  print('continue previous training...')\n",
        "  print()\n",
        "  checkpoint = torch.load(\"./model_%s_%s.tar\" % (TERM, TYPE_INDEX))\n",
        "  model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "  optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "  epoch = checkpoint[\"epoch\"]\n",
        "  list_train_loss=df_performance['train_loss'].values.tolist()\n",
        "  list_valid_loss=df_performance['valid_loss'].values.tolist()\n",
        "  SWITCH_CONTINUE = 'off'\n",
        "\n",
        "for epoch in range(epoch, max_epoch):\n",
        "    print(\"%s epoch\" % (epoch))\n",
        "\n",
        "    train_ = train(model)\n",
        "    list_train_loss.append(train_)\n",
        "    \n",
        "    # 学習途中の状態を保存する。 #https://pystyle.info/pytorch-save-and-load-model/\n",
        "    torch.save(\n",
        "        {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "         },\n",
        "         \"model_%s_%s.tar\" % (TERM, TYPE_INDEX),\n",
        "    )\n",
        "\n",
        "    valid_ = validation(model)\n",
        "    list_valid_loss.append(valid_)\n",
        "\n",
        "    print(df_performance.columns)\n",
        "    df_performance.loc[epoch]['train_loss']=list_train_loss[epoch]\n",
        "    df_performance.loc[epoch]['valid_loss']=list_valid_loss[epoch]\n",
        "    # df_performance['train_loss']=list_train_loss[epoch]\n",
        "    # df_performance['valid_loss']=list_val_loss[epoch]\n",
        "    df_performance.to_csv('./%s_%s.csv' % (TERM, TYPE_INDEX))\n",
        "    print(' Added to ./%s_%s.csv.' % (TERM, TYPE_INDEX))\n",
        "\n",
        "    elapsed_time = time.time() - start\n",
        "    print(\" %s epoch  :  %s [sec] → %s\" % (epoch, elapsed_time, pull_Datetime()))\n",
        "    print()\n",
        "print(\"終了時間 : %s [sec] → %s\" % (elapsed_time, pull_Datetime()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 epoch\n",
            "Index(['epoch', 'train_loss', 'valid_loss'], dtype='object')\n",
            " Added to ./S5_L2e-05_B64_E20_H10_R10000_JorP_J.csv.\n",
            " 0 epoch  :  334.094797372818 [sec] → 2021-11-11 01:33:41.497000+09:00\n",
            "\n",
            "1 epoch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['epoch', 'train_loss', 'valid_loss'], dtype='object')\n",
            " Added to ./S5_L2e-05_B64_E20_H10_R10000_JorP_J.csv.\n",
            " 1 epoch  :  667.7168579101562 [sec] → 2021-11-11 01:39:15.101179+09:00\n",
            "\n",
            "2 epoch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta0-YatTvFjP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU8kHNOmlaEE"
      },
      "source": [
        "print('list_train_loss : ', list_train_loss)\n",
        "print('list_valid_loss : ', list_valid_loss)\n",
        "\n",
        "print(valid_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZi5S4PyxQ0p"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plot learning curve\n",
        "plt.figure()\n",
        "plt.plot(list(range(epoch+1)), list_train_loss, 'r-', label='train_loss')\n",
        "plt.plot(list(range(epoch+1)), list_valid_loss, 'b-', label='val_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n",
        "plt.title('%s  %s' % (TERM, TYPE_INDEX))\n",
        "\n",
        "plt.savefig('./loss_%s_%s.jpeg' % (TERM, TYPE_INDEX))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUfgmLZEka9M"
      },
      "source": [
        "#6. 検証"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r1o9FvL8F78"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uuow5vgkcjH"
      },
      "source": [
        "# 検証方法の確認（1バッチ分で計算ロジックに確認）\n",
        "\n",
        "model.eval()# 訓練モードをオフ\n",
        "try:\n",
        "    for idx, batch in enumerate(test_dataloader):\n",
        "        print(idx)\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        with torch.no_grad():   \n",
        "            # 学習済みモデルによる予測結果をpredsで取得     \n",
        "            preds = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask)\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0fVySmpkjux"
      },
      "source": [
        "以下の様な結果が出力されます\n",
        "この確率の様な値（厳密には、この値ををソフトマックス関数に入力すると確率になる）が大きい方のラベルをモデルは分類結果とし予測としています"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjQBUFlnkfw4"
      },
      "source": [
        "## 予測結果の確認\n",
        "print(f'出力:{preds}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4NUw7R9ktzN"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "出力:(tensor([[-5.0226,  5.0193],\n",
        "        [-5.0390,  4.9736],\n",
        "        [ 4.7941, -4.7459],\n",
        "        [-4.9395,  4.6827], device='cuda:0'),)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "238VYB-SkpcS"
      },
      "source": [
        "左からラベルの[0, 1]に対応しており、1つ目のデータであれば、右側の値が大きいのでモデルはラベル1を予測している"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpXPkkLRkzwD"
      },
      "source": [
        "# 比較しやすい様にpd.dataframeへ整形\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# pd.dataframeへ変換（GPUに乗っているTensorはgpu->cpu->numpy->dataframeと変換）\n",
        "logits_df = pd.DataFrame(preds[0].cpu().numpy(), columns=['logit_0', 'logit_1'])\n",
        "## np.argmaxで大き方の値を取得\n",
        "pred_df = pd.DataFrame(np.argmax(preds[0].cpu().numpy(), axis=1), columns=['pred_label'])\n",
        "label_df = pd.DataFrame(b_labels.cpu().numpy(), columns=['true_label'])\n",
        "\n",
        "accuracy_df = pd.concat([logits_df, pred_df, label_df], axis=1)\n",
        "\n",
        "accuracy_df.head()\n",
        "\n",
        "accuracy_df.to_csv('./%s.csv' % TYPE_INDEX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_DmAbeWHhlt"
      },
      "source": [
        "accuracy_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ym-Osozs7vV"
      },
      "source": [
        "accuracy_df['answer'] = (accuracy_df['pred_label'] == accuracy_df['true_label'])\n",
        "list_answer=accuracy_df['answer'].to_list()\n",
        "count_true=list_answer.count(True)\n",
        "print(list_answer)\n",
        "print(count_true)\n",
        "print('accuracy : ',  float(count_true / len(list_answer))*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjh6cRYgig5D"
      },
      "source": [
        "pred_df.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfBW35B6k2rC"
      },
      "source": [
        "上記の様に予測ラベルと正解ラベルを取得して、dataframeへ保存することができました\n",
        "\n",
        "あとは、シンプルに正解率を計算するなり、sklearnを用いて混合行列を作成するなり、好きな様に分類モデルの評価を行うことができる。"
      ]
    }
  ]
}